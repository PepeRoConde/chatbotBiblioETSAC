\documentclass[12pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\usepackage[galician]{babel}
\usepackage{csquotes}

\usepackage{array}
\usepackage{booktabs}            % \toprule \midrule \bottomrule
\usepackage{tabularx}   
\usepackage{verbatim}
\usepackage{tcolorbox}
\usepackage{float}
\usepackage{multicol}
\tcbuselibrary{breakable}
\usepackage[style=ieee,backend=bibtex]{biblatex}  % o style=apa, ieee, etc.
\addbibresource{referencias.bib}

\makeatletter
\let\@makecaption\relax
\makeatother

% Fonts: Palatino for body, Helvetica for headers
\usepackage{mathpazo} % Palatino
\usepackage{helvet}
\usepackage{microtype}

% Decorative initials
\input Eichenla.fd
\newcommand*\initfamily{\usefont{U}{Eichenla}{xl}{n}}
\usepackage{lettrine}

% Colors
\usepackage{xcolor}
\definecolor{techblue}{RGB}{0,51,102}
\definecolor{rosa}{RGB}{196,45,137}
\definecolor{lightgray}{RGB}{100,100,100}

% Headers and footers
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small\textsf{\nouppercase{\leftmark}}}
\fancyhead[R]{\small\textcolor{lightgray}{\thepage}}
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0pt}

% Chapter and section styling
\usepackage{titlesec}
\titleformat{\chapter}[hang]
  {\normalfont\LARGE\bfseries\sffamily\color{rosa}}
  {\thechapter.}{15pt}{}
\titlespacing*{\chapter}{0pt}{-20pt}{30pt}

\titleformat{\section}
  {\normalfont\Large\bfseries\sffamily\color{rosa}}
  {\thesection}{1em}{}

\titleformat{\subsection}
  {\normalfont\large\bfseries\sffamily}
  {\thesubsection}{1em}{}

% Better spacing
\usepackage{setspace}
\setstretch{1.1}
\setlength{\parskip}{0.4em}
\setlength{\parindent}{15pt}

% Table of contents styling
\usepackage{tocloft}
\renewcommand{\cfttoctitlefont}{\LARGE\bfseries\sffamily\color{rosa}}
\renewcommand{\cftchapfont}{\bfseries\sffamily}
\renewcommand{\cftsecfont}{\sffamily}

% Hyperlinks
\usepackage[colorlinks=true,linkcolor=rosa,citecolor=techblue,urlcolor=techblue]{hyperref}

\title{\scshape\Huge\color{rosa}Chatbot para a documentación e normativa da UDC}
\author{
  Marcelo Ferreiro Sánchez\\
  Marcos Grobas Martínez\\
  José Romero Conde
}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
\noindent 
O obxectivo do proxecto é desenvolver un chatbot capaz de solventar dúbidas
acerca do funcionamiento dos procesos burocráticos e de documentación da
Universidade da Coruña (UDC). Para conseguilo optamos por unha arquitectura
xenerativa aumentada por recuperación (RAG), técnica moi empleada para mellorar
o desempeño de chatbots baseados en LLM cando buscan información específica dun
dominio sobre o que o modelo de linguaxe orixinal non foi entrenado. 
\end{abstract}

\tableofcontents
\clearpage

\chapter{Introdución}
\lettrine[lines=3,lraise=0.1,findent=2pt,nindent=0em]{\initfamily{A}}{}burocracia
de calquera campo pode chegar a ser moi complexa e pode chegar a consumir moito
tempo e recursos ás persoas que teñen que lidiar con ela. Os procesos
universitarios non son unha excepción e moitas das persoas involucradas neles
(sexan, alumnos, profesores ou persoal administrativo) os poden atopar
inabarcables ou imposibles de navegar sen axuda.

Neste contexto, apreciouse como podería ser de gran utilidade o desenvolvemento 
dun chatbot capaz de responder a preguntas relacionadas coa documentación e 
normativa da Universidade seguindo a gran tendencia da actualidade de empregar 
chatbots para diversas tarefas.

O obxectivo deste proxecto é desenvolver un chatbot que poida simplificar e 
explicar \textbf{referindo sempre ás fontes burocráticas oficiais} os procesos 
burocráticos e de documentación da Universidade da Coruña (UDC).

O sistema é resultado da unión de compoñentes e técnicas xa ben coñecidas, 
sempre tendo en mente o obxectivo a cumprir. Polo tanto, tratouse máis ben 
dunha tarefa de aplicación e adaptación de técnicas e ferramentas xa existentes 
nun caso particular, antes que de deseño ou resolución de novos problemas.

Se ben este traballo está circunscrito no contexto da asignatura de Técnicas 
Avanzadas de Procesamiento de Linguaxe Natural (TAPLN), debido á súa natureza 
e obxectivo, gran parte do tempo invertido no proxecto dedicouse á tarefa de 
recolección de información para o RAG.

Non existindo unha 'base de datos' oficial da UDC sobre a que un usuario poda 
descargar toda a documentación relativa ao centro, senón que atópase esta 
repartida nas páxinas web dos seus diferentes centros, foi necesario deseñar 
unha solución que nos permita extraela a partir dos seus portais oficiais.

Este tipo de tarefas non son novas no mundo da informática, de feito pertencen 
a unha área máis que consolidada chamada Recuperación de Información (IR) e 
tales métodos que buscan, extraen e organizan información disposta en webs html 
son coñecidos como \emph{crawlers}, parte esencial do traballo final pois para 
asegurar que o sistema sexa capaz de responder á maioría de dúbidas dos 
usuarios, é necesario ter un corpus de toda información mínimamente relevante 
acerca do funcionamento interno da universidade.




\chapter{Solución proposta}
\lettrine[lines=3,lraise=0.1,findent=2pt,nindent=0em]{\initfamily{M}}{}ostrarase
nesta sección a arquitectura xeral do sistema e posteriormente describirase cada
un dos seus compoñentes, sendo estos principalmente o \emph{RAGsystem} e o \emph{Crawler}.

\section{A Arquitectura}
Fundamentalmente e como indicouse antes, o sistema componse de dúas partes
relativamente independientes: \emph{RAGsystem}, que será un modelo de linguaxe grande
(LLM) xa adestrado que recibirá xunto con cada consulta de usuario, unha serie
de documentos (ou fragmentos dos mesmos) para responder mellor á mesma, e por
outra parte, un sistema de \emph{crawling} que ocuparase de navegar as diversas páxinas
e portais da UDC recolectando aquelas que considere que poden conter información
relevante. \\ \\ 
Nas siguientes subseccións explicaranse en detalle o funcionamento interno de
cada parte e cómo interactúan entre elas. Optouse por unha orde de exposición
que siga o fluxo de execución do sistema, é dicir, comezando polo \emph{Crawler}
e seguindo polo \emph{RAGsystem}. Sopesouse seguir a orde cronolóxica do
desenvolvemento do sistema mais concluíuse que introduciría demasiadas exégesis
e reviraría demasiado e sen utilidade a narrativa desta memoria. De calquera
forma, explicarase a evolución das partes que máis cambios sufriron ao longo da
súa implementación.



\section{O \emph{Crawler}} Considerouse que a posesión dun bo volume de datos
sería crucial para resolver o problema a tratar, na maioría dos casos as dúbidas
burocráticas resólvense encontrando o documento adecuado, e de non telo, o
sistema veríase obrigado a comuinicarlle ao usuario que non ten acceso á tal ou
cal información, voltándose completamente inútil. \\ É por iso que a
Recuperación de Información xoga un papel crucial para o RAG. 
\subsection{Selección de páxinas relevantes}
Sendo así, o primeiro problema a solucionar é o de deseñar un bo criterio do 
que é un \textbf{documento relevante} para a aplicación. Se ben tal tarefa 
pódese complicar \textit{ad infinitum} e é un área de estudo activa aínda 
nestes días [\cite{Pezzuti_2025}], neste caso optouse por un enfoque moito máis 
sinxelo, baseándose primariamente na premisa de que esta tarefa non require de 
conxuntos masivos de datos. Só é necesario navegar un certo número de URLs 
(principalmente do directorio raíz de cada facultade), non a totalidade da web, 
polo que pódese permitir descargar páxinas e documentos potencialmente 
pouco relevantes. A información a colleitar ten un límite de tamaño finito e 
razoable: nun escenario extremo, mesmo descargando todas as URLs da UDC, 
estaríase lonxe de requirir terabytes de almacenamento, como sí acontecería 
nun \textit{crawler} de propósito xeral. \\ \\

Deste xeito, a solución proposta sitúase como un método arcaico aínda que funcional,
unha asignación de relevancia binaria (relevante ou non relevante) mediante
\textit{keywords}. Este enfoque, se ben simple, remite aos métodos de
\textit{focused crawling} pioneiros [\cite{Chakrabarti1999}] que sentaron as
bases da recuperación de información temática na web. \\ \\As palabras clave
utilizadas son fixas e propias do ámbito académico e do vocabulario burocrático,
aparecendo tanto en galego, coma en castelán e inglés (véxase o
Apéndice~\ref{app:keywords} para a lista completa).

\subsection{Procesado dos contidos de cada páxina}
Unha vez unha páxina estímase como relevante, é necesario procesar seu contido,
para este caso, procurar presentalo en texto plano, evitando ao máximo posible
decoradores. Mais nunha páxina atópase máis que texto, especialmente neste caso
de uso, moita información burocrática útil para un usario final atoparase nun
documento PDF ligado ao URL, é por iso que o \textit{crawler} tamén os procesa e
converte en texto plano listo para que posteriormente un LLM poda leelos sen
maior complicación. \\ \\ 
Non obstante, este enfoque presenta unha limitación importante: información que
se atope unicamente en imaxes (capturas de pantalla, carteis dixitalizados ou
documentos escaneados) permanece invisible para o \textit{crawler}. \\ Tal
debilidade do sistema fíxose obvia nas primeiras fases de testeo do
\textit{chatbot}, pois este non era capaz de responder a unha pregunta moi
sinxela e básica para os estudantes: "Cantos libros pódense emprestar?". Tras
investigar a casuística e comprobarse que o
\href{https://www.udc.es/es/biblioteca/servizos/prestamo/}{URL onde figura tal
información} foi efectivamente analizada polo crawler, caéuse na conta de que,
se ben a información figura nunha táboa dentro da páxina, esta está en formato
imaxe [ver \ref{figprestamos}], polo que próbase que é necesario aproveitar
mellor a información de cada páxina para cumplir os obxectivo establecido.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{imaxes/prestamos.png}
    \caption{ Táboa de préstamos}
    \label{figprestamos}
\end{figure}



\subsubsection{Procesado de imaxes mediante OCR}
O recoñecemento óptico de caracteres (OCR polas súas siglas en inglés) é unha
técnica que permite extraer texto a partir de imaxes dixitais, se ben o seu uso
máis típico é a dixitalización de documentos físicos escaneados, serve para
calquera imaxe que conteña caracteres, como é o caso. 

Neste caso, implementouse mediante a librería \textit{pytesseract} unha
interface en \textit{Python} do motor OCR \texttt{Tesseract}, creado
inicialmente por HP e mantido actualmente por Google. 

Procesar cada imaxe presente nun URL pode semexar moi custoso
computacionalmente, mais a extracción de texto mediante OCR é verdadeiramente
rápida, isto sumado a que a maioría de imaxes son irrelevantes e de moi pequeno
tamano, otorga a capacidade de poder procesar todas as presentes en calquera
documento sen apenas engadir latencia ao sistema. Como exemplo, o tempo de
procesado de OCR na imaxe da táboa de préstamos [\ref{figprestamos}] foi de
$0.6280$ segundos. \\ \\ Demostrado que é posible e relativamente sinxelo á vez
que barato procesar arquivos de imaxe, é necesario agora demostrar que tal texto
é fidedigno ao realmente existente na mesma. 


Un exemplo que demostra á perfección un caso de uso real é precisamente a táboa
mencionada anteriormente, o texto extráido en crú pódese ver no
apéndice~\ref{app:OCR}. Revisándoo, o texto extráido non asemexa nada parecido á
táboa orixinal, mais hai que ter en mente que non é necesario que sexa
intelixible para o usuario final, senón para o LLM que o debe de analizar. Unha
forma rápida de comrpobar que o chatbot poida ser capaz de entender o texto
extraído (coa complicación de que neste caso está en formato táboa) é pedirlle
mediante un prompt no portal online dalgún LLM comercial, que refaga a táboa por
nós con esa información. Fíxose tal experimento usando ChatGPT-5 e a táboa que
reconstruiu foi a seguinte:
\begin{table}[H]
\centering
\scriptsize
\begin{tabular}{@{}p{0.18\textwidth} p{0.3\textwidth} ccc@{}}
\toprule
\textbf{Grupo} & \textbf{Tipo de usuarios} & \textbf{Nº docs} & \textbf{Días} & \textbf{Renov.} \\
\midrule
\textbf{1} & Estud. Grao (centros propios/adscritos), Mobilidade, Dobre Grao, Graos interuniv., Univ. Sénior & 10 & 10 días & Indef. (Lím. 10) \\
\midrule
\textbf{2} & Estud. másteres/posgraos propios (Fund. UDC), Estud. TFG, PTGAS & 15 & 21 días & Indef. (Lím. 15) \\
\midrule
\textbf{3} & Estud. Doutoramento, Inv. visitante/senior, Inv. predoc./posdoc & 35 & 30 días & Indef. (Lím. 35) \\
\midrule
\textbf{4} & Becarios inv., Pers. contr. inv. \textit{(Exclusión posible)} & 35 & Curso acad. & Indef. (Lím. 35) \\
\midrule
\textbf{5} & PDI UDC (inc. adscritos), Fund. UDC, Prof. emérito/xub./hon., Prof. visitante, Lectores \textit{(Exclusión posible)} & 100 & Curso acad. & Indef. (Lím. 100) \\
\midrule
\textbf{6} & Persoal externo á UDC, Pers. autoriz. Biblioteca & 6 & 10 días & Indef. (Lím. 6) \\
\bottomrule
\end{tabular}
\caption{Táboa reconstruida mediante LLM (ChatGPT-5)}
\end{table}

Se ben existe certa información que o LLM obviou por ser incompleta, a
información importante está presente, demostrando que os LLMs son capaces de
reconstruir e interpretar a información extraída mediante OCR, incluso cando
esté representada en formatos mais complexos como o é unha táboa.

\subsection{Funcionamento interno do \textit{Crawler}}

A implementación proposta usa da librería \textit{Python BeautifulSoup} para
navegar a rede e extraer información das páxinas. O proceso comeza cunha lista
de URLs semente que representa os portais principais da universidade
(concretamente a \textit{homepage} de cada facultade). Para cada URL, o sistema
descarga o contido HTML, extrae todos os enlaces e imaxes presentes na páxina, e
identifica documentos PDF que conteñan termos relacionados coa burocracia
universitaria segundo a lista de \textit{keywords} antes exposta. Os recursos
descargados almacénanse de forma organizada no sistema de ficheiros local,
mentres que un sistema de metadatos rexistra información sobre cada recurso para
optimizar futuras execucións, concretamente garda o \textit{etag} e a data de
última modificación de cada páxina, ademáis da data de descarga. 

En canto ás imaxes, aplícase OCR a todas as presentes en cada documento e
decídese se gardar o texto extraído ou non segundo se presenta máis dun mínimo
de caracteres. Todo este proceso realízase ao final de crawlear cada páxina, os
arquivos de imaxe vanse engadindo a unha pila, e esta é procesada cando xa
extraéronse as hiperreferencias a outras páxinas e os documentos PDF.

Para acelerar o proceso de \textit{crawling} aplicáronse técnicas de
programación concurrente. É posible establecer un número de traballadores aos
cales se lles asignará unha URL como base desde onde iniciar o crawler, deste
xeito, é posible ter múltiples crawlers simultáneamente navegando a rede da
universidade. Para non xerar problemas de lectura/escritura nos ficheiros onde
se escriben os metadatos ou o rexistro de páxinas visitadas, implementáronse
\textit{locks}, deste xeito dous \textit{crawlers} non podrán escribir á vez nun
mesmo documento.

\section{Análise dos datos obtidos mediante o \textit{Crawler}} Tras un facer un
\textit{crawl} sobre as  \textit{homepages} das facultades e escolas da UDC,
obtiveronse un total de 3377 documentos, dos cales 2212 son páxinas
\textit{HTML} e 1165 son documentos \textit{PDF}. 

Debido a que esta práctica está tan enlazada coas técnicas de Recuperación da
Información clásicas, pareceu interesante realizar unha análise máis exploratoria
típica no sector. En concreto estudar a distribución das palabras do vocabulario
e lonxitude dos documentos: 

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imaxes/analisis_documentos.png}
    \caption{Gráficos de distribución de lonxitude de documentos e frecuencia de termos}
    \label{figEDA}
\end{figure}


Deste xeito pódese observar na figura~\ref{figEDA} mostra tanto a distribución
das lonxitudes de cada documento (medida en caracteres), nótese cómo é que
asemellan haber gran cantidade de documentos moi curtos, tal feito non é de
extrañar pois existen moitas páxinas web cun contido moi limitado que só mostra
unha serie de links ou documentos para descargar, de feito, existen ata URLs coa
única finalidade de mostrar unha ou varias imaxes, en tal caso a lonxitude da
mesma será de 0 (se é que tales imaxes non con texto extraíble por OCR), neste
crawleo atopáronse 115 páxinas sen caracteres.

En canto á distribución de frecuencia de termos, é claro que cumple a lei de
Zipf, pos asemella á mesma distribución que adquiren as gráficas de frecuencia
de palabras do vocabulario en calquera outra corpus e lingua.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imaxes/zipf.png}
    \caption{~Frecuencia de termos en diversas linguas [\cite{wikipedia_zipf}]}
    \label{figZipf}
\end{figure}

Na realidade tal propiedade non é de estrañar, pois esta lei cúmplese ata en
linguas sintéticas [\cite{martinez2016zipf}] e móstrase máis a modo de
curiosidade.

En canto á propia distribución de termos no corpus, as 20 palabras máis comúns
(véxase apéndice~\ref{tab:top20}) parecen perfectamente comprensibles, o único
suceso destacable é a presenza de UDC como número 20, mais está perfectamente
xustificado debido a que repítese múltiples veces na gran maioría de documentos
oficiais. Tamén están dispoñobles no apéndice~\ref{tab:bottom20} as 20 palabras
menos frecuentes, onde parece haber palabras sen sentido (posiblemente á raíz de
erros de OCR) facendo un análise para determinar se a fonte de tales palabras é
unha imaxe ou un documento de texto, 



\section{O \textit{RAGsystem}}

O sistema RAG (Retrieval-Augmented Generation) implementado constitúe o núcleo
do chatbot, combinando técnicas de recuperación de información con modelos de
linguaxe xerativos. O proceso de resposta a unha consulta desenvólvese en varias
etapas: primeiro, a pregunta do usuario convértese nun vector mediante
embeddings semánticos que capturan o seu significado; a continuación, este
vector empregase para buscar no vectorstore os documentos máis relevantes
mediante similitude coseno, recuperando os $k$ fragmentos de texto máis próximos
semanticamente á consulta. Para mellorar a calidade da recuperación, o sistema
incorpora un compoñente de reranking baseado en TF-IDF que permite reordenar os
documentos recuperados segundo a súa relevancia léxica, ou ben combinarse de
forma híbrida coas puntuacións vectoriais mediante pesos configurables. Unha vez
identificados os fragmentos máis relevantes, estes incorpóranse como contexto
nunha plantilla de prompt xunto co historial recente da conversación, permitindo
que o modelo de linguaxe (Claude, ChatGPT ou calquera compatible con
\textit{Langchain}) xere unha resposta fundamentada na documentación oficial da
universidade. O sistema mantén un historial de conversación de lonxitude
configurable que permite responder a preguntas que fan referencia a interaccións
previas, dotando ao chatbot de capacidade contextual e conversacional. Ademais,
cada documento recuperado enriquécese con metadatos que inclúen a súa puntuación
de relevancia tanto vectorial como TF-IDF, facilitando a trazabilidad e
verificación das fontes empregadas para xerar cada resposta.


\subsection{Construcción da base de vectores}
[\cite{lewis2020retrieval}] A base de vectores (vectorstore) constrúese a partir
dos documentos recollidos e previamente convertidos a texto plano (.txt) polo
\textit{crawler}. Cada documento é fragmentando despois en varios \textit
{chunks} de tamano configurable, á vez que se establece un \textit{overlap} que
especifica cantos tokens comparten os fragmentos consecutivos, súa utilidade é
impedir que existan referencias cruzadas dentro dun texto non se vexan cortadas
por terminarse o chunk, xa que nese caso o LLM non podería entender o contexto
completo.  

Para o almacenamento e indexación eficiente dos embeddings, emprégase FAISS
(\textit{Facebook AI Similarity Search})~[\cite{johnson2019billion}], unha
biblioteca optimizada para a busca de similaridade en espazos vectoriais de alta
dimensionalidade. FAISS implementa algoritmos de busca aproximada de veciños máis
próximos (ANN, \textit{Approximate Nearest Neighbors}), que permiten realizar
consultas en millóns de vectores de forma eficiente. O proceso funciona do
seguinte xeito: cada chunk de texto convértese nun vector denso (embedding)
mediante un modelo de linguaxe, estes vectores almacénanse nunha estrutura de
índice optimizada, e cando se realiza unha consulta, FAISS calcula rapidamente
os vectores máis similares utilizando medidas de distancia como a similaridade
coseno ou a distancia euclidiana~[\cite{douze2024faiss}].








\subsection{O sistema de recuperación}
O sistema polo que o RAG recibe os documentos relevantes para cada consulta
recibiu múltiples iteraciones e cambios tras varias fases de testeo e
replanteamento teórico. Trátase dun compoñente clave do sistema e non ten unha
solución trivial, pois é un área de investigación moi activa
[\cite{systematic_rag_2025}], poderíase dicir que se ben a área de IR parecía
estar algo estancada nos últimos anos, debido aos bos resultados que alcanzaron
os buscadores web, agora volve a verse moi activa grazas ao xurdimento dos
RAGsystems.

Comezou empregando un sistema de recuperación baseado exclusivamente en
similitude coseno de vectores FAISS. Mais tras comprobar que tal
\textit{approach} podía non dar os resultados esperados, pois da a mesma
importancia a todas as palabras da consulta, non ten en conta cal pode ser a
palabra clave máis relevante. A maioría das consultas (especialmente
burocráticas) van ter moitas palabras moi comúns e repetidas ao longo da
colección de documentos (proceso, documento, normativa) que poden facer que o
sistema recupere documentos pouco relevantes. 

A primeira solución implementada foi aplicar MMR (Maximal Marginal Relevance) no
canto da similaridade coseno. O fundamento detrás desta idea era que deste xeito
non desenvolverianse documentos moi redundantes entre sí, xa que no caso de
existir varios documentos moi relevantes entre sí, súa información útil para a
consulta sería menor, mais durante a experimentación comprobouse que na
realidade non se cumple tal suposición. 

É moi común ver diferentes documentos oficiais que repiten a mesma información
ou varias versións e revisións dun proceso en diferentes documentos. En tal caso
é probable que o sistema devolva un só deles, perdéndose información relevante
ou directamente indicando un proceso obsoleto, xa que prioriza diversidade ante
exhaustuvudade [\cite{carbonell1998mmr}]. Por outra banda, esta problemática
acerca da vixencia temporal dos documentos é unha das maiores problemáticas
neste proxecto (e en calquera RAG que manexe información cambiante ao longo do
tempo [\cite{grofsky2025freshness}]) e tratarase máis adiante, xa que require
modificación en diversas partes do sistema. 

Sabendo que o MMR mom é axeitado ao noso dominio, decidiuse volver cara o
enfoque orixinal, pero esta buscando a maneira de discriminar mellor entre os
términos relevantes e irrelevantes, existe un método que consegue estes
resultados desde fai tempo, o TF-IDF (Term Frequency - Inverse Document
Frequency) [\cite{sparck_jones1972}]. A forma de aplicalo inicialmente foi
utilizalo para rerankear os documentos recuperados polo FAISS, é dicir, cos n
documentos devoltos mediante a similaridade coseno, estes reordéanse segundo a
ponderación tf-idf. Prontamente caeuse na conta de que deste xeito non obtense
resultados demasiado óptimos pois simplemente cambia de orde os documentos
retrieveados polo FAISS, mais non engade novos documentos que poidan ser
relevantes e que a similaridade coseno obvia. Por iso, a solución final foi
empregar un sistema híbrido, onde se combinan as puntuacións de similitude
coseno e tf-idf mediante pesos configurables (50/50 no caso actual). Tal enfoque
é moi común nos RAGsystems actuais como no caso de \cite{regulatory_hybrid_2025}
e \cite{adobe_hybrid_2024}.







\section{Os modelos}
\section{Ferramentas usadas}

\chapter{Instalación e uso}





\chapter{Validación e resultados}
% \lettrine[lines=3,lraise=0.1,findent=2pt,nindent=0em]{\initfamily{R}}{}esults presentation here.
\section{Validación do sistema RAG}

\subsection{Complexidade da validación}
A validación dun sistema Retrieval-Augmented Generation (RAG) é intrinsecamente complexa debido á súa natureza híbrida, xa que combina dous subsistemas conceptualmente distintos pero fortemente acoplados: o módulo de \textit{retrieval}, encargado de seleccionar a información relevante, e o módulo de \textit{generation}, responsable de producir a resposta final condicionada polo contexto recuperado. Avaliar correctamente un sistema RAG implica analizar de forma separada e conxunta ambos compoñentes, así como a súa interacción, incrementando notablemente a dificultade do proceso de validación \cite{rag_eval_survey_2024}.

Ademais, unha avaliación rigorosa require a disposición de conxuntos de datos anotados e métricas específicas para cada etapa do pipeline. A literatura sinala que a definición de \textit{ground truth} fiable —cun conxunto completo de documentos relevantes e respostas correctas— é custosa en tempo e recursos, e que as métricas existentes poden verse afectadas pola variabilidade na anotación humana \cite{rag_eval_survey_2024,llm_judge_eval_2024}.

\subsection{Conxunto de validación}
Para realizar unha avaliación práctica e reproducible dentro das limitacións do proxecto, construíuse un conxunto de validación reducido composto por \textbf{25 preguntas}. Cada pregunta está asociada a unha resposta esperada e ao documento concreto do corpus onde se atopa a información necesaria para resolvela. Na maioría dos casos, a información relevante localízase de forma explícita nun único documento.

É importante destacar que esta avaliación realízase sobre un \textbf{corpus reducido e controlado de documentos}. Este corpus representa só unha fracción do conxunto total de documentos que o sistema RAG manexará nun contexto real, onde se espera que haxa moitos máis documentos, algúns dos cales poderían recuperarse sen ser necesarios para responder a consulta concreta. Traballar cun corpus acotado permite, con todo, illar variables e analizar de forma precisa o comportamento do sistema. En particular, pódese estudar o impacto de parámetros como estratexias de recuperación, métricas de similitude, tamaño de chunk ou número de documentos recuperados, aspectos relevantes no deseño práctico de sistemas RAG \cite{rag_required_abilities_2023}.


Esta aproximación debe considerarse \textbf{subestimada e conservadora}, xa que en escenarios reais poderían existir múltiples documentos relevantes por consulta non cubertos neste estudo. As métricas obtidas non buscan medir o rendemento absoluto do sistema en produción, senón servir como base experimental para estudar o impacto relativo das distintas decisións de deseño do RAG.

\subsection{Evaluación do módulo de \textit{retrieval}}
O módulo de recuperación avalíase de forma independente mediante métricas clásicas de \textit{Information Retrieval}, adaptadas ao contexto dun sistema RAG:

\begin{itemize}
    \item \textbf{Recall@10}: proporción de documentos relevantes que aparecen entre los 10 primeros resultados recuperados. Calculase como a fracción de documentos relevantes presentes no top-10 do ranking. Aínda que presentamos principalmente o \textbf{recall fraccional}, convén aclarar que neste conxunto de validación cada pregunta adoita ter un único documento relevante. Polo tanto, nesta situación o recall fraccional é practicamente equivalente ao \textbf{recall binario}, que indica se polo menos un documento relevante aparece entre os top-10. Esta métrica reflicte a capacidade do sistema de garantir que a información esencial chega ao modelo xerativo.
    \item \textbf{MRR (Mean Reciprocal Rank)}: penaliza a aparición tardía do primeiro documento relevante no ranking. Calculase como o recíproco da posición do primeiro documento relevante atopado (1 se é o primeiro, 0.5 se é o segundo, etc.). Esta métrica reflicte a rapidez coa que o sistema proporciona información útil ao LLM.
    \item \textbf{Precision@10}: proporción de \textit{chunks} recuperados que pertencen a documentos relevantes dentro dos 10 primeiros resultados. Avalía a capacidade do sistema para minimizar a recuperación de información irrelevante, especialmente crítico en corpus grandes ou ruidosos. Esta métrica é a nivel de chunk, reflectindo o nivel de “ruído” que chega ao LLM.
\end{itemize}

No noso sistema, o \textbf{recall e o MRR calcúlase a nivel de documento}, considerando cada documento como unha unidade discreta de relevancia. Isto simplifica a avaliación e garante que se mida a efectividade do sistema en levar información esencial ao modelo xerativo, independentemente de como os documentos estean fragmentados en chunks para a súa utilización polo LLM. 

Pola súa banda, a \textbf{precision} calcúlase a nivel de chunk, como proporción de fragments pertencentes a documentos relevantes entre os recuperados. Este enfoque mixto (recall a nivel documento, precision a nivel chunk) proporciona unha visión útil para o desempeño do sistema RAG: asegura que a información clave está dispoñible para o LLM, ao mesmo tempo que avalía a calidade do material recuperado.

\subsection{Evaluación da xeración}
A avaliación do módulo de xeración céntrase en dúas dimensións complementarias:

\begin{itemize}
    \item \textbf{Answer Relevance}: mide se a resposta aborda correctamente a pregunta e evita información irrelevante. Esta métrica non xulga a veracidade, só a pertinencia.
    \item \textbf{Answer Faithfulness}: avalía se as afirmacións contidas na resposta están efectivamente respaldadas polo contexto recuperado polo módulo de \textit{retrieval}, detectando posibles alucinacións ou información non soportada.
\end{itemize}

\subsubsection{Mecanismo de avaliación: \textit{LLM-as-judge}}
Para automatizar a avaliación empregouse un modelo de linguaxe avanzado (\textbf{GPT-5.2}) como avaliador (\textit{LLM-as-judge}), garantindo capacidade suficiente para xulgar de forma coherente e consistente as respostas do xerador \cite{llm_judge_eval_2024}. Este enfoque permite unha avaliación máis detallada que as métricas clásicas, incorporando aspectos de completitude, coherencia e consistencia co contexto.

\paragraph{Faithfulness}
O LLM analiza cada resposta dividíndoa en afirmacións atómicas e comproba se cada unha está efectivamente respaldada polo contexto recuperado. O score final, entre 0 e 1, representa a proporción de afirmacións verificadas. Ademais, xérase unha explicación detallada que identifica que afirmacións fallaron e por que, permitindo unha maior transparencia na avaliación e a detección de posibles alucinacións ou inclusión de información externa ao contexto.

\paragraph{Relevance}
A relevancia mide se a resposta aborda todos os puntos da pregunta de forma concisa e útil, evitando información irrelevante ou redundante. Tamén retorna un score entre 0 e 1 e unha explicación que describe posibles omisións ou exceso de información.

\paragraph{Beneficios do enfoque}

O uso de \textit{LLM-as-judge} permite:
\begin{itemize}
    \item Avaliar fidelidade e pertinencia de respostas en linguaxe natural de forma consistente e reproducible.
    \item Detectar matices de completitude, coherencia e relevancia que métricas de IR tradicionais non capturan.
    \item Reducir a dependencia do etiquetado humano para a avaliación detallada de respostas.
\end{itemize}

\subsection{Consideracións sobre o corpus reducido}
O estudo realizouse sobre un \textbf{corpus reducido e controlado de documentos}. Isto permite illar variables e analizar o impacto de parámetros como: as estratexias de recuperación (TF-IDF, híbridas, reranking) ou o tamaño de chunk e superposición

En escenarios de produción, con moitos máis documentos dispoñibles, é altamente probable que o sistema recupere unha maior cantidade de documentos irrelevantes, o que afectará especialmente á \textbf{precision@10}. O estudo realizado neste corpus reducido proporciona unha visión inicial sobre a capacidade do RAG para filtrar información relevante en presenza de ruído documental, e serve como base experimental para estudar o impacto relativo das decisións de deseño.

\subsection{Limitacións}
O conxunto reducido introduce certas limitacións que afectan a toda a validación:
\begin{itemize}
    \item Non reflicte a heteroxeneidade nin a escala real do corpus.
    \item Subrepresenta casos que requiren integración multi-documento.
    \item Posibles omisións no etiquetado humano.
    \item As métricas non son directamente extrapolables a produción.
\end{itemize}

A avaliación proposta proporciona unha visión relativa do impacto das decisións
de deseño do RAG, e non debe interpretarse como unha medida directa do seu
rendemento absoluto en escenarios de produción \cite{rag_eval_survey_2024}.


\chapter{Conclusions e traballos futuros}

\section{Extensións da validación}
A avaliación presentada neste traballo céntrase en métricas clásicas de recuperación e en criterios básicos de calidade da xeración, o cal resulta adecuado para un estudo controlado cun conxunto de validación construído manualmente. Esta elección responde a unha decisión metodolóxica orientada a garantir reproducibilidade, trazabilidade e consistencia na avaliación, máis que a unha limitación conceptual do enfoque.

A literatura recente sinala que o comportamento dun sistema RAG en escenarios reais depende tamén dun conxunto de capacidades máis avanzadas (\textit{required abilities}), cuxa avaliación resulta máis complexa e require condicións experimentais específicas, como datasets deseñados ad hoc e un maior volume de anotación humana \cite{rag_eval_survey_2024}.

Como liña de traballo futuro, resulta recomendable ampliar a validación cara á avaliación destas capacidades, entre as que se inclúen:
\begin{itemize}
    \item \textbf{Noise robustness}: capacidade de xestionar documentos ruidosos semanticamente relacionados coa pregunta pero sen información útil para a resposta.
    \item \textbf{Negative rejection}: habilidade do sistema para recoñecer contextos insuficientes e evitar a xeración de respostas especulativas.
    \item \textbf{Information integration}: capacidade para combinar información procedente de múltiples documentos relevantes en preguntas complexas.
    \item \textbf{Counterfactual robustness}: aptitude para detectar e ignorar información incorrecta ou contraditoria presente nos documentos recuperados.
\end{itemize}

A incorporación destas dimensións permitiría unha avaliación máis completa do sistema RAG, pero implicaría a ampliación do conxunto de validación actual ou a creación de novos datasets específicos, así como un maior investimento en anotación humana e deseño experimental. Estas extensións constitúen, por tanto, unha continuidade natural deste traballo,
orientada a aproximar a avaliación ás condicións reais de uso e a analizar o
comportamento do sistema en escenarios máis complexos e variados \cite{rag_required_abilities_2023}.




\printbibliography
\appendix

\chapter{Lista completa de \textit{keywords}}
\label{app:keywords}

A continuación móstrase o conxunto completo de palabras clave utilizadas
polo \textit{crawler} para determinar a relevancia das páxinas:

\begin{multicols}{3}
\small
\begin{itemize}
    \item regulation
    \item reglamento
    \item normativa
    \item procedure
    \item procedimiento
    \item proceso
    \item form
    \item formulario
    \item solicitud
    \item guideline
    \item guia
    \item manual
    \item policy
    \item politica
    \item norma
    \item enrollment
    \item matricula
    \item inscripcion
    \item administrative
    \item administrativo
    \item academic
    \item academico
    \item calendar
    \item calendario
    \item syllabus
    \item programa
    \item requirements
    \item requisitos
    \item regulamento
    \item regulación
    \item procedemento
    \item solicitude
    \item guía
    \item docente
    \item asignatura
    \item política
    \item matrícula
    \item inscrición
    \item académico
    \item convocatoria
    \item prazo
    \item prazos
    \item documentación
    \item tramite
    \item trámite
    \item ordenanza
    \item resolución
    \item circular
    \item instrucións
    \item instrucciones
    \item bases
    \item anexo
    \item catalog
    \item catalogo
    \item catálogo
    \item library
    \item biblioteca
    \item collection
    \item coleccion
    \item colección
    \item acquisition
    \item adquisicion
    \item adquisición
    \item loan
    \item prestamo
    \item préstamo
    \item reserve
    \item reserva
    \item interlibrary
    \item interbibliotecario
    \item reference
    \item referencia
    \item circulation
    \item circulacion
    \item circulación
    \item periodical
    \item periodico
    \item periódico
    \item journal
    \item revista
    \item archive
    \item archivo
    \item arquivos
    \item repository
    \item repositorio
    \item classification
    \item clasificacion
    \item clasificación
    \item indexing
    \item indexacion
    \item indexación
    \item cataloging
    \item catalogacion
    \item catalogación
    \item dewey
    \item isbn
    \item issn
    \item bibliographic
    \item bibliografico
    \item bibliográfico
    \item holdings
    \item fondos
    \item serials
    \item publicacions seriadas
    \item special collections
    \item coleccions especiais
    \item reading room
    \item sala de lectura
    \item stacks
    \item depósito
    \item microfilm
    \item microficha
    \item digital library
    \item biblioteca dixital
    \item opac
    \item marc
    \item application
    \item deadline
    \item plazo
    \item documentation
    \item documentacion
    \item certification
    \item certificado
    \item certificación
    \item authorization
    \item autorizacion
    \item autorización
    \item notification
    \item notificacion
    \item notificación
    \item registration
    \item registro
    \item protocol
    \item protocolo
    \item statute
    \item estatuto
    \item ordinance
    \item decree
    \item decreto
    \item resolution
    \item resolucion
    \item official
    \item oficial
    \item office
    \item oficina
    \item department
    \item departamento
    \item service
    \item servicio
    \item servizo
    \item unit
    \item unidad
    \item unidade
\end{itemize}
\end{multicols}
\chapter{Saída OCR da táboa de exemplo}
\label{app:OCR}
\begin{tcolorbox}[
    title=Texto OCR,
    colback=rosa,
    colframe=rosa!80!black,
    fontupper=\small,
    fonttitle=\small\bfseries,
    breakable,  % Permite dividir en varias páginas si es necesario
    boxrule=0.5pt,
    arc=3pt,
    outer arc=3pt,
    left=5pt,
    right=5pt,
    top=3pt,
    bottom=3pt,
    before skip=10pt,
    after skip=10pt,
    width=\textwidth,  % Asegura que no se salga del ancho de página
    coltitle=black]
\begin{spacing}{0.85}  % Reduce el interlineado ligeramente
[Tipos de usuarios

N? de documentos en préstamo

Días de préstamo

Renovaciones

Reservas

GRUPO 1

Estudiantado de Grado de centros propios y adscritos

Estudiantado de programa de movilidad (Erasmus, Sicue-Séneca)

Estudiantado de doble Grado, de simultaneidad 10 10 días Indefinidas | Límite 10 docs.
Estudiantado de grados interuniversitarios
Estudiantado da Universidad Séntor
GRUPO 2
Estudiantado de MASTERES e posgrados propios, incluyendo los
dela Fundación Universidade da Coruña . ,
15 21 días Indefinidas | Límite 15 docs.
Estudiantado de Trabajos de fin de grado.
Personal de administración en servicio (PTGAS)
GRUPO 3
Estudiantado de Doctorado 35 30 días Indefinidas | Límite 35 does.
Personal investigador visitante; visitant tant
'ersonal investigador visitante: visitante senior] visitante 35 30 días indefinidas | Límite 38 docs
predoctoral o postdactoral
GRUPO 4
Becarios/as de investigación Curso académico
Personal contratado investigador (cada biblioteca podrá excluir
35 de este tipo de préstamo Indefinidas | Límite 35 docs.
documentos par razón de uso y
disponibilidad)
GRUPO 5
PDI da UDC (incluyendo centros adscritos), de la Fundación UDC Curso académico
Profesorado emérito, jubilado incentivado y honorario (cada biblioteca podrá excluir
Profesorado visitante 100 de este tipo de préstamo Indefíridas | Límite 100 docs.
Lectores/as documentos par razón de uso y
disponibilidad)
GRUPO 6
Cual ! idad taria de la UDC
cualquier persona ajena a la comunidad universitaria dela 6 10 días indefinidas | Límite 6 docs

que sea autorizada por la Biblioteca Universitaria


\end{spacing}
\end{tcolorbox}
\chapter{Análise de frecuencias léxicas}

\section{Palabras máis frecuentes}

\begin{table}[H]
\centering
\begin{tabular}{rllr}
\toprule
\textbf{Pos.} & \textbf{Palabra} & & \textbf{Frecuencia} \\
\midrule
1  & de     & - & 385,703 \\
2  & a      & - & 113,823 \\
3  & en     & - & 102,598 \\
4  & la     & - & 102,014 \\
5  & e      & - & 90,196 \\
6  & y      & - & 77,587 \\
7  & que    & - & 73,069 \\
8  & o      & - & 57,323 \\
9  & da     & - & 49,975 \\
10 & el     & - & 48,951 \\
11 & para   & - & 43,204 \\
12 & do     & - & 40,254 \\
13 & se     & - & 35,387 \\
14 & los    & - & 35,200 \\
15 & del    & - & 33,793 \\
16 & las    & - & 29,507 \\
17 & por    & - & 27,315 \\
18 & no     & - & 25,683 \\
19 & con    & - & 25,326 \\
20 & udc    & - & 25,182 \\
\bottomrule
\end{tabular}
\caption{Top 20 palabras máis frecuentes no corpus}
\label{tab:top20}
\end{table}

\section{Palabras menos frecuentes}

\begin{table}[H]
\centering
\begin{tabular}{rllr}
\toprule
\textbf{Pos.} & \textbf{Palabra} & & \textbf{Frecuencia} \\
\midrule
1  & ricondo              & - & 1 \\
2  & acompahamento        & - & 1 \\
3  & recomendaciéns       & - & 1 \\
4  & aproximacién         & - & 1 \\
5  & nosum                & - & 1 \\
6  & climent              & - & 1 \\
7  & vengut               & - & 1 \\
8  & empar                & - & 1 \\
9  & retransmision        & - & 1 \\
10 & toxicoloxia          & - & 1 \\
11 & landeira             & - & 1 \\
12 & angelines            & - & 1 \\
13 & psicoloxicos         & - & 1 \\
14 & mase                 & - & 1 \\
15 & lameiras             & - & 1 \\
16 & cartelixornadasumisionquimicaevs & - & 1 \\
17 & conciliacións        & - & 1 \\
18 & conciliaciones       & - & 1 \\
19 & operatoria           & - & 1 \\
20 & extranjeos           & - & 1 \\
\bottomrule
\end{tabular}
\caption{Top 20 palabras menos frecuentes no corpus}
\label{tab:bottom20}
\end{table}

\end{document}
