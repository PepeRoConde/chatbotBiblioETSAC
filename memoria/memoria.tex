\documentclass[12pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\usepackage[galician]{babel}
\usepackage{csquotes}
\usepackage{xltabular}  % Mejor para tablas largas con texto
\usepackage{makecell} 
\usepackage{listings}
\usepackage{array}
\usepackage{booktabs}            % \toprule \midrule \bottomrule
\usepackage{tabularx}   
\usepackage{verbatim}
\usepackage{fancyvrb}
\usepackage{tcolorbox}
\usepackage{float}
\usepackage{multicol}
\usepackage{enumitem}
\tcbuselibrary{breakable}
\usepackage[style=ieee,backend=bibtex]{biblatex}  % o style=apa, ieee, etc.
\addbibresource{referencias.bib}

\makeatletter
\let\@makecaption\relax
\makeatother

% Fonts: Palatino for body, Helvetica for headers
\usepackage{mathpazo} % Palatino
\usepackage{helvet}
\usepackage{microtype}

% Decorative initials


\usepackage{lettrine}

% Colors
\usepackage{xcolor}
\definecolor{techblue}{RGB}{0,51,102}
\definecolor{rosa}{RGB}{196,45,137}
\definecolor{lightgray}{RGB}{100,100,100}
\definecolor{rosa1}{RGB}{181, 60, 135}
\definecolor{rosa2}{RGB}{200, 80, 150}
\definecolor{rosa3}{RGB}{220, 100, 165}
\definecolor{rosa4}{RGB}{240, 130, 185}

\definecolor{rosaprincipal}{RGB}{181, 60, 135}


\usepackage{yfonts}
\renewcommand*\initfamily[1]{{\color{rosa}\fontsize{70}{70}\selectfont\scalebox{2}{\textgoth{#1}}}}
% Estilo de tcolorbox único
\tcbset{
    testbox/.style={
        colback=rosaprincipal!10,
        colframe=rosaprincipal,
        fonttitle=\bfseries
    }
}

\lstset{
    basicstyle=\small\ttfamily,
    breaklines=true,
    breakatwhitespace=true,
    columns=flexible,
    keepspaces=true
}
\tcbset{
    promptbox/.style={
        colback=rosaprincipal!10,
        colframe=rosaprincipal,
        fonttitle=\bfseries,
        breakable
    }
}
% Headers and footers
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small\textsf{\nouppercase{\leftmark}}}
\fancyhead[R]{\small\textcolor{lightgray}{\thepage}}
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0pt}

% Chapter and section styling
\usepackage{titlesec}
\titleformat{\chapter}[hang]
  {\normalfont\LARGE\bfseries\sffamily\color{rosa}}
  {\thechapter.}{15pt}{}
\titlespacing*{\chapter}{0pt}{-20pt}{30pt}

\titleformat{\section}
  {\normalfont\Large\bfseries\sffamily\color{rosa}}
  {\thesection}{1em}{}

\titleformat{\subsection}
  {\normalfont\large\bfseries\sffamily}
  {\thesubsection}{1em}{}

% Better spacing
\usepackage{setspace}
\setstretch{1.1}
\setlength{\parskip}{0.4em}
\setlength{\parindent}{15pt}

% Table of contents styling
\usepackage{tocloft}
\renewcommand{\cfttoctitlefont}{\LARGE\bfseries\sffamily\color{rosa}}
\renewcommand{\cftchapfont}{\bfseries\sffamily}
\renewcommand{\cftsecfont}{\sffamily}

% Hyperlinks
\usepackage[colorlinks=true,linkcolor=rosa,citecolor=techblue,urlcolor=techblue]{hyperref}

\title{\scshape\Huge\color{rosa}Chatbot para a documentación e normativa da UDC}
\author{
  Marcelo Ferreiro Sánchez\\
  Marcos Grobas Martínez\\
  José Romero Conde
}
\date{\today}

\begin{document}

\pagenumbering{roman}
\maketitle

\begin{abstract}
\noindent 
O obxectivo do proxecto é desenvolver un chatbot capaz de solventar dúbidas
acerca do funcionamiento dos procesos burocráticos e de documentación da
Universidade da Coruña (UDC). Para conseguilo optamos por unha arquitectura
xenerativa aumentada por recuperación (RAG), técnica moi empleada para mellorar
o desempeño de chatbots baseados en LLM cando buscan información específica dun
dominio sobre o que o modelo de linguaxe orixinal non foi entrenado. 
\end{abstract}

\tableofcontents
\clearpage

\pagenumbering{arabic}
\chapter{Introdución}
\lettrine[lines=3,lraise=0.1,findent=2pt,nindent=0em]{\initfamily{A}}{}burocracia
de calquera campo pode chegar a ser moi complexa e pode chegar a consumir moito
tempo e recursos ás persoas que teñen que lidiar con ela. Os procesos
universitarios non son unha excepción e moitas das persoas involucradas neles
(sexan, alumnos, profesores ou persoal administrativo) os poden atopar
inabarcables ou imposibles de navegar sen axuda.

Neste contexto, apreciouse como podería ser de gran utilidade o desenvolvemento 
dun chatbot capaz de responder a preguntas relacionadas coa documentación e 
normativa da Universidade seguindo a gran tendencia da actualidade de empregar 
chatbots para diversas tarefas.

O obxectivo deste proxecto é desenvolver un chatbot que poida simplificar e 
explicar \textbf{referindo sempre ás fontes burocráticas oficiais} os procesos 
burocráticos e de documentación da Universidade da Coruña (UDC).

O sistema é resultado da unión de compoñentes e técnicas xa ben coñecidas, 
sempre tendo en mente o obxectivo a cumprir. Polo tanto, tratouse máis ben 
dunha tarefa de aplicación e adaptación de técnicas e ferramentas xa existentes 
nun caso particular, antes que de deseño ou resolución de novos problemas.

Se ben este traballo está circunscrito no contexto da asignatura de Técnicas 
Avanzadas de Procesamiento de Linguaxe Natural (TAPLN), debido á súa natureza 
e obxectivo, gran parte do tempo invertido no proxecto dedicouse á tarefa de 
recolección de información para o RAG.

Non existindo unha 'base de datos' oficial da UDC sobre a que un usuario poda 
descargar toda a documentación relativa ao centro, senón que atópase esta 
repartida nas páxinas web dos seus diferentes centros, foi necesario deseñar 
unha solución que nos permita extraela a partir dos seus portais oficiais.

Este tipo de tarefas non son novas no mundo da informática, de feito pertencen 
a unha área máis que consolidada chamada Recuperación de Información (IR) e 
tales métodos que buscan, extraen e organizan información disposta en webs html 
son coñecidos como \emph{crawlers}, parte esencial do traballo final pois para 
asegurar que o sistema sexa capaz de responder á maioría de dúbidas dos 
usuarios, é necesario ter un corpus de toda información mínimamente relevante 
acerca do funcionamento interno da universidade.




\chapter{Solución proposta}
\lettrine[lines=3,lraise=0.1,findent=2pt,nindent=0em]{\initfamily{M}}{}ostrarase
nesta sección a arquitectura xeral do sistema proposto e, a continuación,
describirase en detalle cada un dos seus compoñentes principais, sendo estes o
\emph{Crawler} e o \emph{RAG system}. O obxectivo desta arquitectura é combinar
un mecanismo de adquisición automática de información con un modelo de
linguaxe capaz de xerar respostas fundamentadas en contido externo e actualizado.

\section{A Arquitectura}
De maneira xeral, o sistema componse de dúas partes funcionalmente diferenciadas
pero fortemente interconectadas. Por unha banda, o sistema de \emph{crawling},
encargado de explorar e percorrer de forma automatizada os distintos portais e
páxinas web da Universidade da Coruña (UDC), co fin de descargar e
almacenar aqueles documentos que potencialmente conteñen información relevante.
Por outra banda, o \emph{RAG system}, concibido como unha pipeline de
procesamento da información que integra mecanismos de recuperación e xeración,
é o responsable de atender as consultas dos usuarios e producir respostas en
linguaxe natural apoiadas en contido externo recuperado. \\ \\ Nas siguientes subseccións explicaranse en detalle o funcionamento interno de
cada parte e cómo interactúan entre elas. Optouse
por unha orde de exposición que siga o fluxo de execución do sistema, comezando
polo \emph{Crawler} e continuando polo \emph{RAG system}. Aínda que se considerou
presentar o desenvolvemento seguindo a orde cronolóxica da implementación,
descartouse esta opción ao introducir unha carga expositiva innecesaria e
dificultar a comprensión global da arquitectura. De calquera
forma, explicarase a evolución das partes que máis cambios sufriron ao longo da
súa implementación.



\section{O \emph{Crawler}} Considerouse que a posesión dun bo volume de datos
sería crucial para resolver o problema a tratar, na maioría dos casos as dúbidas
burocráticas resólvense encontrando o documento adecuado, e de non telo, o
sistema veríase obrigado a comuinicarlle ao usuario de que non dispón da información solicitada, limitando
significativamente a súa capacidade para ofrecer respostas útiles. É por iso que a
Recuperación de Información xoga un papel crucial para o RAG. 

\subsection{Selección de páxinas relevantes}
Sendo así, o primeiro problema a abordar é o deseño dun criterio axeitado para
determinar que se considera un \textbf{documento relevante} no contexto da
aplicación. Trátase dunha cuestión que pode complicarse \textit{ad infinitum}
e que continúa a ser unha área de estudo activa na literatura recente
\cite{Pezzuti_2025}. Porén, no marco deste traballo optouse por un enfoque moito
máis sinxelo e pragmático.

Esta decisión baséase na premisa de que a tarefa non require o manexo de
conxuntos masivos de datos nin a exploración exhaustiva da web. Abonda con
navegar un número limitado de URLs, principalmente pertencentes aos
directorios raíz das distintas facultades e servizos da UDC, polo que resulta
aceptable descargar páxinas e documentos potencialmente pouco relevantes.
Ademais, o volume total de información a recoller presenta un límite de tamaño finito e razoable. Mesmo nun escenario extremo no que se descargasen todas as URLs asociadas á UDC, o espazo de almacenamento necesario estaría moi lonxe das ordes de magnitude propias dun \textit{crawler} de propósito xeral, onde si se require xestionar volumes de datos a escala de terabytes. Esta abordabilidade é posible grazas a que, unha vez descargadas, as páxinas e documentos son procesados de forma estruturada, permitindo unha xestión eficiente do contido.

Deste xeito, a solución proposta concíbese como un método sinxelo pero funcional,
baseado nunha asignación de relevancia binaria (\emph{relevante} ou
\emph{non relevante}) a partir de \textit{keywords}. A pesar da súa simplicidade,
este enfoque está estreitamente relacionado cos métodos pioneiros de
\textit{focused crawling} \cite{Chakrabarti1999}, que sentaron as bases para a
recuperación de información temática na web.

As palabras clave seleccionadas son fixas e específicas do ámbito académico e
do vocabulario burocrático da universidade, aparecendo en galego, castelán e
inglés. Para consultar a lista completa, véxase o Apéndice~\ref{app:keywords}.


\subsection{Procesado dos contidos de cada páxina}
Unha vez unha páxina se considera relevante, é necesario procesar o seu
contido para presentalo, sempre que sexa posible, en texto plano, evitando
decoradores e elementos innecesarios --como menús, cabeceiras, pés de páxina, publicidade ou elementos visuais que non aportan contido relevante--. Para iso, o \emph{crawler} encárgase de
\emph{parsear} a estrutura da páxina, extraendo o contido textual relevante
de HTML e outros elementos web. No caso de uso deste traballo, moita
información burocrática útil para o usuario final atópase en documentos PDF
ligados ao URL; por iso, o \emph{crawler} tamén se encarga de extraer, parsear e converter estes ficheiros a texto plano. Dispoñer do contido en texto plano permite posteriormente dividir os documentos en \emph{chunks}, xerar \emph{embeddings} e construír \emph{vector stores}, permitiendo así a recuperación e xeración eficiente de respostas no sistema RAG.


Non obstante, este enfoque presenta unha limitación importante: calquera
información que apareza exclusivamente en formato de imaxe (capturas de
pantalla, carteis dixitalizados ou documentos escaneados) permanece
invisible para o \emph{crawler}. Esta debilidade fíxose evidente nas primeiras
fases de probas do \emph{chatbot}, cando o sistema non foi capaz de responder
a unha pregunta básica para estudantes: ``Cantos libros pódense
emprestar?''. Tras investigar o caso e verificar que a
\href{https://www.udc.es/es/biblioteca/servizos/prestamo/}{páxina correspondente}
fóra efectivamente analizada polo \emph{crawler}, comprobouse que, aínda que a
información figura nunha táboa dentro da páxina, esta estaba en formato
imaxe (véxase \ref{figprestamos}). Este exemplo evidencia que é necesario
aproveitar mellor a información dispoñible en cada páxina para cumprir os
obxectivos establecidos.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{imaxes/prestamos.png}
    \caption{ Táboa de préstamos}
    \label{figprestamos}
\end{figure}



\subsubsection{Procesado de imaxes mediante OCR}
O recoñecemento óptico de caracteres (OCR, polas súas siglas en inglés) é unha
técnica que permite extraer texto a partir de imaxes dixitais. A súa aplicación
máis habitual é a dixitalización de documentos físicos escaneados, mais tamén
pode empregarse en calquera imaxe que conteña caracteres, como é o caso neste
traballo. Para este fin, implementouse unha interface en \textit{Python} utilizando
a librería \textit{pytesseract}, que actúa como envoltorio do motor OCR
\texttt{Tesseract} \Cite{tesseract_ocr_github}, inicialmente creado por HP e actualmente mantido por Google.

Procesar cada imaxe presente nun URL pode parecer custoso desde o punto de
vista computacional; con todo, a extracción de texto mediante OCR resulta
realmente rápida. Ademais, a maioría das imaxes son irrelevantes e de tamaño
pequeno, polo que é posible procesar todas as imaxes dun documento sen
incorrer en latencia significativa no sistema. Por exemplo, o tempo de procesado
OCR na imaxe da táboa de préstamos [\ref{figprestamos}] foi de $0.6280$ segundos.

Unha vez demostrado que o procesado é rápido, cómpre avaliar a fidelidade do
texto extraído respecto do contido orixinal da imaxe. Neste sentido, a táboa
mencionada anteriormente serve como exemplo real de uso: o texto extraído en
crú pódese consultar no Apéndice~\ref{app:OCR}. A pesar de que o texto extraído
non se asemella directamente á táboa orixinal, isto non supón un problema para
o sistema, pois o LLM é quen debe interpretalo e estruturalo adecuadamente. Un
xeito práctico de verificar isto consiste en solicitarlle ao modelo que
reconstrúa a táboa a partir da información OCR; este experimento realizouse
empregando ChatGPT-5, e a táboa reconstruída demostrou que o modelo pode
comprender e organizar a información de forma útil para o usuario.

\begin{table}[H]
\centering
\scriptsize
\begin{tabular}{@{}p{0.18\textwidth} p{0.3\textwidth} ccc@{}}
\toprule
\textbf{Grupo} & \textbf{Tipo de usuarios} & \textbf{Nº docs} & \textbf{Días} & \textbf{Renov.} \\
\midrule
\textbf{1} & Estud. Grao (centros propios/adscritos), Mobilidade, Dobre Grao, Graos interuniv., Univ. Sénior & 10 & 10 días & Indef. (Lím. 10) \\
\midrule
\textbf{2} & Estud. másteres/posgraos propios (Fund. UDC), Estud. TFG, PTGAS & 15 & 21 días & Indef. (Lím. 15) \\
\midrule
\textbf{3} & Estud. Doutoramento, Inv. visitante/senior, Inv. predoc./posdoc & 35 & 30 días & Indef. (Lím. 35) \\
\midrule
\textbf{4} & Becarios inv., Pers. contr. inv. \textit{(Exclusión posible)} & 35 & Curso acad. & Indef. (Lím. 35) \\
\midrule
\textbf{5} & PDI UDC (inc. adscritos), Fund. UDC, Prof. emérito/xub./hon., Prof. visitante, Lectores \textit{(Exclusión posible)} & 100 & Curso acad. & Indef. (Lím. 100) \\
\midrule
\textbf{6} & Persoal externo á UDC, Pers. autoriz. Biblioteca & 6 & 10 días & Indef. (Lím. 6) \\
\bottomrule
\end{tabular}
\caption{Táboa reconstruida mediante LLM (ChatGPT-5)}
\end{table}

Se ben existe certa información que o LLM obviou por ser incompleta, a
información importante está presente, demostrando que os LLMs son capaces de
reconstruir e interpretar a información extraída mediante OCR, incluso cando
esté representada en formatos mais complexos como o é unha táboa. 

\subsection{Funcionamento interno do \textit{Crawler}}

A implementación proposta usa da librería \textit{Python BeautifulSoup} para
navegar a rede e extraer información das páxinas. O proceso comeza cunha lista
de URLs semente que representa os portais principais da universidade
(concretamente a \textit{homepage} de cada facultade). Para cada URL, o sistema
descarga o contido HTML, extrae todos os enlaces e imaxes presentes na páxina, e
identifica documentos PDF que conteñan termos relacionados coa burocracia
universitaria segundo a lista de \textit{keywords} antes exposta. Os recursos
descargados almacénanse de forma organizada no sistema de ficheiros local,
mentres que un sistema de metadatos rexistra información sobre cada recurso para
optimizar futuras execucións, concretamente garda o \textit{etag}, a data de
última modificación de cada páxina, a data de descarga e o hash do contido.

En canto ás imaxes, aplícase OCR a todas as presentes en cada documento. O
proceso realízase en dúas fases consecutivas: primeiro procésase coa libraría
\texttt{img2table} (deseñada para extraer texto de táboas en imaxes) e, se esta
primeira fase non extrae un número mínimo de caracteres, entón aplícase un
segundo OCR utilizando \texttt{pytesseract} de xeito estándar. O texto extraído
por OCR intégrase directamente no contido textual da páxina á que pertence a
imaxe (sempre e cando alcance un número mínimo de caracteres definido): engádese
ao ficheiro de texto correspondente cun \textit{header} que indica a súa orixe
(\texttt{[TÁBOA OCR]} ou \texttt{[IMAXE OCR]}), permitindo así conservar tanto
o texto HTML como o contido visual nun único documento estruturado.

Todo este procesamento realízase ao final de \textit{crawlear} cada páxina:
primeiro extráense as hiperreferencias a outras páxinas e documentos PDF, e
despois procesanse as imaxes encoladas para OCR. Esta estratexia minimiza o
cuello de botella que se produciría se o OCR se realizase de forma síncrona
mentres se descargan outros recursos.

Para acelerar o proceso de \textit{crawling} aplicáronse técnicas de programación
concurrente. É posible establecer un número de traballadores (\textit{workers})
aos cales se lles asigna unha URL como punto de partida, permitindo múltiples
crawlers simultáneamente navegando a rede. Para evitar problemas de escritura
nos ficheiros de metadatos ou rexistro de páxinas visitadas, implementáronse
\textit{locks}, garantindo que dous crawlers non poidan escribir á vez nun mesmo
recurso.

Antes de procesar cada documento, comprobanse os metadatos para determinar se o
contido cambiou desde o último crawleo. Primeiro verifica os campos
\texttt{last\_modified} e \texttt{etag}; se se detecta unha modificación, extráese
o texto completo e calcúlase un hash do contido. Se este hash é diferente do
hash previo, a variable booleana \texttt{needs\_embeddings} actívase, indicando
que o documento debe ser vectorizado no seguinte paso. Deste xeito, evítase xerar
embeddings para documentos que non cambiaron, optimizando tanto o tempo de
procesamento como o uso de recursos.

En conxunto, esta combinación de crawling distribuído, OCR en dúas fases, xestión
eficiente de imaxes e metadatos, e comprobación de cambios mediante hash garante
que o crawler funcione de forma rápida, escalable e eficiente, mantendo a
información relevante organizada e lista para o procesamento posterior, como se
mostra nas gráficas do apéndice~\ref{fig:crawlerRun}.


\section{Análise dos datos obtidos mediante o \textit{Crawler}} 

Tras facer un \textit{crawl} sobre as \textit{homepages} das facultades e escolas da UDC, obtiveronse un total de 4.966 documentos, dos cales 2.668 son páxinas \textit{HTML} e 2.298 documentos \textit{PDF} (véxase~\ref{fig:file_types_distribution}).  

Debido á relación coas técnicas clásicas de Recuperación da Información, realizouse unha análise exploratoria do vocabulario e da lonxitude dos documentos: 

\begin{table}[h]
\centering
\caption{Estadísticas del corpus}
\label{tab:corpus_stats}
\begin{tabular}{lr}
\hline
\textbf{Métrica} & \textbf{Valor} \\
\hline
Arquivos procesados & 4.966 \\
Total de caracteres & 75.088.461 \\
Total de palabras & 10.164.265 \\
Tamaño del vocabulario & 73.640 \\
Palabras únicas (hapax legomena) & 15.889 \\
\hline
\end{tabular}
\end{table}

Atopáronse 10.164.265 palabras cun vocabulario de 73.640 termos, das cales
15.889 aparecen só unha vez (\textit{hapax legomena}), un 20\% do vocabulario. A
maioría non son erros: só 230 son faltas ortográficas e 30 xeradas polo OCR.
Este fenómeno de vocabulario de uso desigual segue a lei de Zipf, onde poucas
palabras son moi frecuentes e moitas son raras, como se mostra nas
Figuras~\ref{figZipf} e~\ref{figEDA}\footnote{Para saber máis información sobre
este curioso suceso recoméndase encarecidamente ver o vídeo de \textit{Vsauce}
\cite{vsauce2015zipf} sobre o tema}.  


Tamén se observa o principio de Pareto: aproximadamente o 20\% das palabras máis
frecuentes representan arredor do 80\% das ocorrencias, aínda que neste corpus a
relación é máis extrema: o 2,1\% do vocabulario alcanza o 80\% das ocorrencias e
o 20\% cobre o 97,5\%.  

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imaxes/zipf.png}
    \caption{Frecuencia de termos en diversas linguas \cite{wikipedia_zipf}}
    \label{figZipf}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imaxes/analisis_corpus.png}
    \caption{Gráficos de distribución de lonxitude de documentos e frecuencia de termos}
    \label{figEDA}
\end{figure}

A distribución das lonxitudes dos documentos (Figura~\ref{figEDA}, esquerda)
mostra moitos documentos curtos: mediana de 4.200 caracteres e media de 15.121,
indicando asimetría debido a documentos longos que elevan a media. Moitas
páxinas web teñen contido limitado ou só mostran ligazóns ou imaxes. No
\textit{crawleo} detectáronse 115 páxinas baleiras (0 caracteres), ben por
conter só imaxes sen texto extraíble por OCR, ben por ser redireccións ou
navegación pura.









\section{O \textit{RAGsystem}}

O sistema RAG (Retrieval-Augmented Generation) implementado constitúe o núcleo
do chatbot, combinando técnicas de recuperación de información con modelos de
linguaxe xerativos. O proceso de resposta a unha consulta desenvólvese nun fluxo
secuencial e optimizado:

Inicialmente, a consulta do usuario pasa por un módulo de \textit{clasificación}
realizado por un modelo de linguaxe lixeiro (Claude Haiku) para determinar se
require recuperación de documentación. Cando é necesaria, a mesma consulta é
\textit{reescrita} (\textit{query rewriting}) para mellorar a súa formulación
tanto para a busca semántica como léxica.

Para a recuperación, empregase un sistema \textit{híbrido} que combina busca
densa (mediante embeddings semánticos e similitude coseno en FAISS) e busca
léxica (usando BM25, unha evolución do TF-IDF). As puntuacións de ambos métodos
fusiónanse con pesos determinados empiricamente,
seleccionando os $k$ fragmentos de texto máis relevantes da base de documentos
da universidade.

Os documentos recuperados, xunto coa consulta orixinal e o historial de
conversación (de lonxitude configurable), intégranse nun prompt estruturado.
Este pasa a un modelo de linguaxe grande (Claude Sonnet) escollido pola súa
capacidade de razoamento e, especialmente, pola súa efectividade na comunicación
entre axentes e o seguimento de instrucións complexas
\cite{claude-agents-2024}. O modelo xera así unha resposta precisa
fundamentada na documentación oficial.

O sistema enriquece cada documento recuperado con metadatos que inclúen as súas
procedencias (hipervínculos), datas (de actualización da páxina), puntuacións de
relevancia tanto da busca densa como da léxica, garantindo total trazabilidade e
permitindo a verificación das fontes utilizadas en cada resposta.

\subsection{Construción da base de vectores}
\cite{lewis2020retrieval} A base de vectores (\textit{vectorstore}) constrúese
a partir dos documentos recollidos e previamente convertidos a texto plano
(.txt) polo \textit{crawler}. Cada documento é fragmentado en varios
\textit{chunks} de tamaño configurable, establecéndose tamén un \textit{overlap}
que especifica cantos \textit{tokens} comparten os fragmentos consecutivos. A
utilidade deste solapamento é impedir que referencias cruzadas ou ideas contidas
nun texto queden cortadas arbitrariamente ao final dun \textit{chunk}, xa que
nese caso o LLM non podería comprender o contexto completo.

Cada fragmento de texto (\textit{chunk}) xera, ademais do seu contido, un
conxunto de metadatos que inclúen: o hipervínculo de orixe da páxina, a data da
última actualización do documento orixinal (obtida durante o \textit{crawling})
e outros campos auxiliares para a trazabilidade. Estes metadatos almacénanse
xunto co vector resultante e son recuperados co texto durante a busca, o que
permite ao sistema referenciar a fonte exacta e avaliar a vixencia da
información.

Para o almacenamento e indexación eficiente dos \textit{embeddings}, emprégase
FAISS (\textit{Facebook AI Similarity Search}) \cite{johnson2019billion}, unha
biblioteca optimizada para a busca de similaridade en espazos vectoriais de alta
dimensionalidade. FAISS implementa algoritmos de busca aproximada de veciños
máis próximos (ANN, \textit{Approximate Nearest Neighbors}), que permiten
realizar consultas en millóns de vectores de forma eficiente. O proceso funciona
do seguinte xeito: cada \textit{chunk} de texto convértese nun vector denso
(\textit{embedding}) mediante un modelo de linguaxe especializado; estes
vectores almacénanse, xunto cos seus metadatos, nunha estrutura de índice
optimizada; e cando se realiza unha consulta, FAISS calcula rapidamente os
vectores máis similares utilizando medidas de distancia como a similaridade
coseno ou a distancia euclidiana~\cite{douze2024faiss}.






\subsection{O sistema de recuperación}

O sistema polo que o RAG recibe os documentos relevantes para cada consulta
recibe múltiples iteracións e cambios tras varias fases de testeo e
replanteamento teórico. Trátase dun compoñente clave do sistema e non ten unha
solución trivial, pois é un área de investigación moi activa
\cite{systematic_rag_2025}. Poderíase dicir que, aínda que a área de RI
(Recuperación de Información) parecía estar algo estancada nos últimos anos
debido aos bos resultados que alcanzaron os buscadores web, agora volve a verse
moi activa grazas ao xurdimento dos sistemas RAG.

Inicialmente, o sistema empregou un método de recuperación baseado
exclusivamente na similitude coseno sobre vectores FAISS. Porén, durante as
primeiras probas comprobouse que esta aproximación podía non ofrecer os
resultados esperados, xa que daba a mesma importancia a todas as palabras da
consulta, sen ter en conta cal podería ser a palabra clave máis relevante. A
maioría das consultas, especialmente aquelas de carácter burocrático, conteñen
moitas palabras comúns e repetidas ao longo da colección de documentos (como
\textit{proceso}, \textit{documento} ou \textit{normativa}), o que podía facer
que o sistema recuperase documentos pouco relevantes.

Como primeira mellora, implementouse MMR (Maximal Marginal Relevance) en lugar
da similitude coseno. A idea subxacente era que, deste xeito, non se
recuperarían documentos redundantes entre si, xa que se existisen varios
documentos moi similares, a súa información adicional para a consulta sería
limitada. Non obstante, durante a experimentación observouse que esta suposición
non se cumpría no noso dominio. É moi común atopar diferentes documentos
oficiais que repiten a mesma información, ou varias versións e revisións dun
proceso en distintos documentos. Neses casos, o sistema tendía a devolver só un
deles, perdéndose información relevante ou, incluso, indicando un proceso xa
obsoleto, ao priorizar a diversidade fronte á exhaustividade
\cite{carbonell1998mmr}. Esta problemática, relacionada coa vixencia temporal
dos documentos, constitúe un dos maiores retos deste proxecto (e de calquera
sistema RAG que manipule información cambiante ao longo do tempo
\cite{grofsky2025freshness}) e será tratada con maior detalle máis adiante, xa
que require modificacións en diversas partes do sistema.

Unha vez comprobado que o MMR non era axeitado para o noso dominio, retomouse o
enfoque orixinal, pero buscando unha maneira de discriminar mellor entre os
termos relevantes e irrelevantes da consulta. Para iso, decidiuse explorar
métodos clásicos de recuperación, como o TF-IDF (Term Frequency – Inverse
Document Frequency) \cite{sparck_jones1972}. A primeira aplicación consistiu
en usalo para reordenar (\textit{reranking}) os documentos xa recuperados por
FAISS. Con todo, axiña se observou que esta estratexia non ofrecía resultados
óptimos, xa que simplemente cambiaba a orde dos documentos recuperados, sen
engadir novos documentos relevantes que puidesen ser ignorados pola similitude
coseno.

A solución final adoptada foi un sistema híbrido que combina as puntuacións da
similitude coseno (recuperación densa) e do BM25 (unha mellora sobre o TF-IDF
para recuperación léxica ou dispersa), mediante pesos configurables. Despois
dunha avaliación da literatura, no inicio, estableceuse un balance de 50/50 entre
ambos métodos, un enfoque común en sistemas RAG actuais
\cite{regulatory_hybrid_2025}, \cite{adobe_hybrid_2024}, máis unha vez
deseñado un \textit{pipeline} para realizar validación, optouse por usar tal
experimento para determinar empíricamente o mellor valor de peso, ademáis do
mellor \textit{chunk size}.

Ademais, o fluxo de recuperación intégrase dentro dunha canle máis ampla de
procesamento da consulta. Antes de realizar a búsqueda, lévasse a cabo unha
\textit{clasificación da consulta} (mediante un LLM lixeiro, como Claude Haiku)
para determinar se é necesario recuperar documentos. En caso afirmativo,
aplícase un \textit{reescrito da consulta} (\textit{query rewriting}), co
obxectivo de optimizar a súa formulación para a busca tanto no índice denso
(FAISS) como no léxico (BM25). Os documentos recuperados por este sistema
híbrido, xunto coa consulta orixinal, pásanlle finalmente a un modelo de
linguaxe máis grande (como Claude Sonnet) para xerar a resposta final.





\subsection{Os modelos}

A elección dos modelos de linguaxe no sistema RAG realizouse atendendo a
criterios de eficiencia, latencia e rendemento específico para cada tarefa do
fluxo. O sistema emprega de xeito estratéxico modelos de diferentes capacidades
segundo a súa función dentro da arquitectura, optimizando así o balance entre
precisión, tempo de resposta e custo.

Para as tarefas iniciais de procesamento da consulta (clasificación para
determinar a necesidade de recuperación de documentos e reescritura
(\textit{query rewriting}) para mellorar a formulación da busca) utilízase
\textbf{Claude Haiku}. Este modelo, sendo o máis rápido e económico da familia
Claude de Anthropic, resulta adecuado para tarefas lixeiras de comprensión e
transformación textual que non requiren razoamento profundo pero si baixa
latencia.

Para a fase central de xeración da resposta empregase \textbf{Claude Sonnet}.
Este modelo ofrece un equilibrio óptimo entre capacidades de razoamento,
seguimento de instrucións complexas e eficiencia, sendo especialmente adecuado
para sintetizar información de múltiples documentos e producir respostas
coherentes, precisas e ben fundamentadas. A súa capacidade para traballar con
\textit{prompts} estruturados que inclúen contexto recuperado, historial de
conversación e instrucións específicas de formato resulta clave para a calidade
final do sistema.

A separación de responsabilidades entre modelos lixeiros para tarefas previas e
modelos máis capaces para a xeración final segue unha práctica común en
arquitecturas de sistemas RAG, destinada a minimizar a latencia e o custo
computacional sen comprometer a calidade das respostas
\cite{lakshmanan2024rag}, \cite{gao2023retrieval}. Neste proxecto, a elección
de Claude Haiku e Sonnet implementa esta estratexia adaptándoa aos recursos e
limitacións do noso entorno.


\subsubsection{Xestión de vixencia dos documentos}
Como xa foi mencionado anteriormente, o problema de tratar cun \textit{corpus}
destas caracterísitcas é o averiguar se un documento dispoñible foi derrogado ou
non, é moi común que as páxinas que os manteñen non sexan borradas e sigan
mostrándoo como se seguera tendo relevancia. Tal problemática non é única a esta
aplicación enconcreto pois constité un dos grandes campos de investigacións dos
\textit{Ragsystems}. 

A solución proposta e implementada ten unha parte de extracción de información,
é tarefa do \textit{crawler} asignar a cada documento retribuído unha data (o
campo \textit{last\_modified} de cada URL), mais en caso de que tal dato non sexa
accesible (o server da páxina non o mostra), a responsabilidade de otrogarlle
unha data de vixencia aos documentos recae no LLM, isto conseguese engadindo a
obriga de intentar sempre dar unha data de cada fonte de información ao
\textit{prompt} inicial. 

Na práctica poderíase pensar que na maioría dos casos o llm non será capaz de
atopar unha data no documento, máis facendo unha breve búsqueda sobre o
\textit{corpus} as ocurrencias de datas son moi comúns, de feito un 67\% dos
documentos que non dispoñel de \textit{last\_modified} teñen algunha data neles
que o LLM analizará como válida (ou non).

Deste xeito conséguese que o RAGsystem non só preste atención á vixencia das
fontes que utiliza, senón que poderá dar información temporal das mesmas.

No apéndice pódese apreciar unha consulta simple \ref{fig:temporal} ao sistema e cómo este é capaz
de referir á data.



\section{Ferramentas usadas}

AS ferramentas principais da que nosa implementación fai uso son as seguintes:
\begin{itemize}
\item \textbf{LangChain} - Licenza: MIT~\cite{mit-license}
\item \textbf{Anthropic Claude API} - Licenza: Propietaria
\item \textbf{Mistral AI API} - Licenza: Propietaria
\item \textbf{Sentence Transformers} - Licenza: Apache 2.0~\cite{apache-license}
\item \textbf{FAISS} - Licenza: MIT
\item \textbf{PyTorch} - Licenza: BSD-3-Clause~\cite{bsd-license}
\item \textbf{Transformers (Hugging Face)} - Licenza: Apache 2.0
\item \textbf{OpenCV} - Licenza: Apache 2.0
\item \textbf{Tesseract OCR} - Licenza: Apache 2.0
\item \textbf{Pandas} - Licenza: BSD-3-Clause
\item \textbf{Scikit-learn} - Licenza: BSD-3-Clause
\end{itemize}










\chapter{Instalación e uso}





\chapter{Validación e resultados}
% \lettrine[lines=3,lraise=0.1,findent=2pt,nindent=0em]{\initfamily{R}}{}esults presentation here.
\section{Validación do sistema RAG}

\subsection{Complexidade da validación}
A validación dun sistema Retrieval-Augmented Generation (RAG) é intrinsecamente
complexa debido á súa natureza híbrida, xa que combina dous subsistemas
conceptualmente distintos pero fortemente acoplados: o módulo de
\textit{retrieval}, encargado de seleccionar a información relevante, e o módulo
de \textit{generation}, responsable de producir a resposta final condicionada
polo contexto recuperado. Avaliar correctamente un sistema RAG implica analizar
de forma separada e conxunta ambos compoñentes, así como a súa interacción,
incrementando notablemente a dificultade do proceso de validación
\cite{rag_eval_survey_2024}.

Ademais, unha avaliación rigorosa require a disposición de conxuntos de datos
anotados e métricas específicas para cada etapa do pipeline. A literatura sinala
que a definición de \textit{ground truth} fiable —cun conxunto completo de
documentos relevantes e respostas correctas— é custosa en tempo e recursos, e
que as métricas existentes poden verse afectadas pola variabilidade na anotación
humana \cite{rag_eval_survey_2024,llm_judge_eval_2024}.

\subsection{Conxunto de validación}
Para realizar unha avaliación práctica e reproducible dentro das limitacións do
proxecto, construíuse un conxunto de validación reducido composto por \textbf{25
preguntas}. Cada pregunta está asociada a unha resposta esperada e ao documento
concreto do corpus onde se atopa a información necesaria para resolvela. Na
maioría dos casos, a información relevante localízase de forma explícita nun
único documento.

É importante destacar que esta avaliación realízase sobre un \textbf{corpus
reducido e controlado de documentos}. Este corpus representa só unha fracción do
conxunto total de documentos que o sistema RAG manexará nun contexto real, onde
se espera que haxa moitos máis documentos, algúns dos cales poderían recuperarse
sen ser necesarios para responder a consulta concreta. Traballar cun corpus
acotado permite, con todo, illar variables e analizar de forma precisa o
comportamento do sistema. En particular, pódese estudar o impacto de parámetros
como estratexias de recuperación, métricas de similitude, tamaño de chunk ou
número de documentos recuperados, aspectos relevantes no deseño práctico de
sistemas RAG \cite{rag_required_abilities_2023}.


Esta aproximación debe considerarse \textbf{subestimada e conservadora}, xa que
en escenarios reais poderían existir múltiples documentos relevantes por
consulta non cubertos neste estudo. As métricas obtidas non buscan medir o
rendemento absoluto do sistema en produción, senón servir como base experimental
para estudar o impacto relativo das distintas decisións de deseño do RAG.

\subsection{Evaluación do módulo de \textit{retrieval}} O módulo de recuperación
avalíase de forma independente mediante métricas clásicas de \textit{Information
Retrieval}, adaptadas ao contexto dun sistema RAG:

\begin{itemize}
    \item \textbf{Recall@10}: proporción de documentos relevantes que aparecen
    entre los 10 primeros resultados recuperados. Calculase como a fracción de
    documentos relevantes presentes no top-10 do ranking. Aínda que presentamos
    principalmente o \textbf{recall fraccional}, convén aclarar que neste
    conxunto de validación cada pregunta adoita ter un único documento
    relevante. Polo tanto, nesta situación o recall fraccional é practicamente
    equivalente ao \textbf{recall binario}, que indica se polo menos un
    documento relevante aparece entre os top-10. Esta métrica reflicte a
    capacidade do sistema de garantir que a información esencial chega ao modelo
    xerativo.
    \item \textbf{MRR (Mean Reciprocal Rank)}: penaliza a aparición tardía do
    primeiro documento relevante no ranking. Calculase como o recíproco da
    posición do primeiro documento relevante atopado (1 se é o primeiro, 0.5 se
    é o segundo, etc.). Esta métrica reflicte a rapidez coa que o sistema
    proporciona información útil ao LLM.
    \item \textbf{Precision@10}: proporción de \textit{chunks} recuperados que
    pertencen a documentos relevantes dentro dos 10 primeiros resultados. Avalía
    a capacidade do sistema para minimizar a recuperación de información
    irrelevante, especialmente crítico en corpus grandes ou ruidosos. Esta
    métrica é a nivel de chunk, reflectindo o nivel de “ruído” que chega ao LLM.
\end{itemize}

No noso sistema, o \textbf{recall e o MRR} calcúlase a nivel de documento,
considerando cada documento como unha unidade discreta de relevancia. Isto
simplifica a avaliación e garante que se mida a efectividade do sistema en levar
información esencial ao modelo xerativo, independentemente de como os documentos
estean fragmentados en chunks para a súa utilización polo LLM. 

Pola súa banda, a \textbf{precision} calcúlase a nivel de chunk, como proporción
de fragments pertencentes a documentos relevantes entre os recuperados. Este
enfoque mixto (recall a nivel documento, precision a nivel chunk) proporciona
unha visión útil para o desempeño do sistema RAG: asegura que a información
clave está dispoñible para o LLM, ao mesmo tempo que avalía a calidade do
material recuperado.

\subsection{Evaluación da xeración}
A avaliación do módulo de xeración céntrase en dúas dimensións complementarias:

\begin{itemize}
    \item \textbf{Answer Relevance}: mide se a resposta aborda correctamente a
    pregunta e evita información irrelevante. Esta métrica non xulga a
    veracidade, só a pertinencia.
    \item \textbf{Answer Faithfulness}: avalía se as afirmacións contidas na
    resposta están efectivamente respaldadas polo contexto recuperado polo
    módulo de \textit{retrieval}, detectando posibles alucinacións ou
    información non soportada.
\end{itemize}

\subsubsection{Mecanismo de avaliación: \textit{LLM-as-judge}} Para automatizar
a avaliación empregouse un modelo de linguaxe avanzado (\textbf{GPT-5.2}) como
avaliador (\textit{LLM-as-judge}), garantindo capacidade suficiente para xulgar
de forma coherente e consistente as respostas do xerador
\cite{llm_judge_eval_2024}. Este enfoque permite unha avaliación máis detallada
que as métricas clásicas, incorporando aspectos de completitude, coherencia e
consistencia co contexto.

\paragraph{Faithfulness}
O LLM analiza cada resposta dividíndoa en afirmacións atómicas e comproba se
cada unha está efectivamente respaldada polo contexto recuperado. O score final,
entre 0 e 1, representa a proporción de afirmacións verificadas. Ademais, xérase
unha explicación detallada que identifica que afirmacións fallaron e por que,
permitindo unha maior transparencia na avaliación e a detección de posibles
alucinacións ou inclusión de información externa ao contexto.

\paragraph{Relevance}
A relevancia mide se a resposta aborda todos os puntos da pregunta de forma
concisa e útil, evitando información irrelevante ou redundante. Tamén retorna un
score entre 0 e 1 e unha explicación que describe posibles omisións ou exceso de
información.

\paragraph{Beneficios do enfoque}

O uso de \textit{LLM-as-judge} permite:
\begin{itemize}
    \item Avaliar fidelidade e pertinencia de respostas en linguaxe natural de forma consistente e reproducible.
    \item Detectar matices de completitude, coherencia e relevancia que métricas de IR tradicionais non capturan.
    \item Reducir a dependencia do etiquetado humano para a avaliación detallada de respostas.
\end{itemize}


\subsubsection{Uso do mecanismo de avaliación como métrica}
Anteriormente fíxose referencia a como empregariamos o \textit{pipeline} de
avaliación para atopar un máximo no espacio de hiperparámetros do modelo, sendo
estes o \textit{chunk size} e o peso entre a busca densa e a dispersa.

Tal experimentación requiriu dunha \textit{grid search} que mediu cinco métricas
para cada combinación de valores: tres propias de Recuperación de Información
(\textit{Recall}, \textit{Precision} e \textit{MRR}) e dúas propias da
avaliación con \textit{LLM-as-judge} (\textit{Faithfulness} e
\textit{Relevance}). Tras promediar os valores para cada pregunta, puidéronse
construir \textit{heatmaps} para cada unha das medicións (ver
Figura~\ref{fig:heatmap_metrics}).

métricas para valores máis altos do peso asignado a BM25 (busca léxica) fronte á
busca densa (FAISS). A puntuación final de cada documento no sistema híbrido 
calcúlase mediante a combinación lineal:

\begin{equation}
Score_{final} = Score_{denso} + \alpha \cdot Score_{disperso}
\label{eq:score_hibrido}
\end{equation}



onde $\alpha$ representa o peso relativo de BM25. Cando $\alpha > 1$, como no 
valor óptimo de 1.6 atopado, a busca léxica ten maior influencia na selección 
final. Isto indica que, para o dominio específico da documentación
burocrática universitaria, a recuperación baseada en coincidencia de termos
clave é especialmente efectiva. As consultas neste contexto adoitan incluír
nomes propios de formularios, códigos de procedementos ou termos técnicos moi
específicos, onde a recuperación léxica supera á semántica pura. Este fenómeno é
consistente coa literatura que destaca a superioridade de BM25 en dominios con
vocabulario especializado e baixa variación lexical \cite{lin2022lexical}.
Ademais, a natureza formal e estándar da linguaxe administrativa fai que os
documentos relevantes compartan termos exactos coas consultas, situación onde os
métodos de recuperación tradicional baseados en termos aínda ofrecen vantaxes
sobre os enfoques puramente semánticos.

Debido a que é necesario elixir un par de valores para os hiperparámetros,
optouse por aqueles que maximizan a métrica de \textit{Relevance} obtida
mediante \textit{LLM-as-judge}. Esta decisión baséase na premisa de que a
relevancia percibida da resposta final é o criterio de calidade máis alineado
coa experiencia do usuario final nun sistema de preguntas e respostas. Mentres
que métricas tradicionais de RI como \textit{Precision} e \textit{Recall} miden
a eficacia da recuperación de documentos, a \textit{Relevance} evalúa
directamente se o contido xerado responde de maneira útil e adecuada á intención
da consulta orixinal. Maximizar esta métrica prioriza que o sistema produza
respostas substanciais e directamente aplicables, por riba doutras
consideracións como a exhaustividade bruta (\textit{Recall}) ou a minimización
de información irrelevante (\textit{Precision}) no contexto recuperado. Esta
aproximación está avalada por investigacións recentes que suxiren que, en
sistemas RAG interactivos, a relevancia da resposta xerada é o predictor máis
forte da satisfacción do usuario \cite{saad2024evaluating}.

Polo tanto, tras facer un \textit{surface plot}
(Figura~\ref{fig:surface_plots_contour}) da \textit{Relevance} (e tamén da
\textit{Faithfulness}), optouse polo par de valores no seu cumio (que o
maximizan), sendo este un peso de 1.6 para BM25 e un \textit{chunk size} de 2048
\textit{tokens}. Tamén se realizou un \textit{heatmap} de todas estas métricas
promediadas (Figura~\ref{fig:heatmap_combined}), onde o par de valores con
mellor puntuación segue sendo o mesmo.

Non é de estrañar que o \textit{chunk size} óptimo para este dominio sexa
relativamente grande. A documentación burocrática e administrativa universitaria
adoita estar estruturada en seccións longas e autocontidas (como procedementos
completos, regulamentos ou guías), onde o contexto local é crucial para
comprender requisitos, excepcións ou pasos interrelacionados. Fragmentos
demasiado pequenos poden separar información conceptualmente unida, dificultando
que o modelo de linguaxe xere respostas coherentes e exhaustivas. Este resultado
é consistente coa literatura sobre recuperación en dominios técnicos e legais,
onde se recomiendan tamaños de fragmento maiores para preservar a integridade
semántica dos documentos \cite{wang2023chunking}.



\subsection{Consideracións sobre o corpus reducido}
O estudo realizouse sobre un \textbf{corpus reducido e controlado de
documentos}. Isto permite illar variables e analizar o impacto de parámetros
como: as estratexias de recuperación (TF-IDF, híbridas, reranking) ou o tamaño
de chunk e superposición

En escenarios de produción, con moitos máis documentos dispoñibles, é altamente
probable que o sistema recupere unha maior cantidade de documentos irrelevantes,
o que afectará especialmente á \textbf{precision@10}. O estudo realizado neste
corpus reducido proporciona unha visión inicial sobre a capacidade do RAG para
filtrar información relevante en presenza de ruído documental, e serve como base
experimental para estudar o impacto relativo das decisións de deseño.

\subsection{Limitacións}
O conxunto reducido introduce certas limitacións que afectan a toda a validación:
\begin{itemize}
    \item Non reflicte a heteroxeneidade nin a escala real do corpus.
    \item Subrepresenta casos que requiren integración multi-documento.
    \item Posibles omisións no etiquetado humano.
    \item As métricas non son directamente extrapolables a produción.
\end{itemize}

A avaliación proposta proporciona unha visión relativa do impacto das decisións
de deseño do RAG, e non debe interpretarse como unha medida directa do seu
rendemento absoluto en escenarios de produción \cite{rag_eval_survey_2024}.


\chapter{Conclusions e traballos futuros}


\lettrine[lines=3,lraise=0.1,findent=2pt,nindent=0em]{\initfamily{N}}{}este
traballo desenvolveuse un \textit{chatbot} baseado en arquitectura RAG para asistir aos
membros da comunidade universitaria da UDC na resolución de dúbidas sobre
procesos burocráticos e documentación oficial. O sistema combina un
\textit{crawler} especializado para a recolleción automática de documentación
dispersa nos portais web da universidade cun sistema híbrido de recuperación que
integra busca densa (FAISS) e dispersa (BM25), xerando respostas fundamentadas
en fontes oficiais verificables mediante modelos de linguaxe.

A arquitectura proposta demostrou ser efectiva. A experimentación sistemática
revelou que no dominio da documentación administrativa universitaria, a
recuperación dispersa xoga un papel especialmente relevante, obtendo un peso
óptimo de 1.6 para BM25 e un tamaño de \textit{chunk} de 2048 \textit{tokens}. O
desenvolvemento do \textit{crawler}, que incorpora técnicas de OCR para extraer
texto de imaxes e táboas, permitiu construír un corpus de case 5.000 documentos
con metadatos de trazabilidad e vixencia temporal. A validación experimental,
mediante métricas clásicas de RI e avaliación con \textit{LLM-as-judge},
confirmou a viabilidade da aproximación, aínda que os resultados non son
directamente extrapolables a un escenario de produción de maior escala.

Como traballos futuros, identifícanse varias liñas prioritarias: ampliar o
conxunto de validación con casos máis complexos, implementar un sistema de
actualización incremental do \textit{crawler}, explorar técnicas máis
avanzadas de \textit{reranking} con modelos especializados, e desenvolver
métodos de razoamento temporal explícito para discriminar entre normativas
vixentes e obsoletas de forma máis robusta.

En conclusión, este proxecto demostra que a aplicación de técnicas de RAG ao
dominio da documentación burocrática universitaria é viable. A
combinación de recuperación híbrida, modelos de linguaxe capaces e metadatos de
trazabilidad proporciona unha base para facilitar o acceso á información
administrativa, contribuíndo a simplificar a interacción dos usuarios coa
burocracia universitaria e liberando tempo para tarefas de maior valor
académico.




\section{Extensións arquitectónicas e metodolóxicas}

Ademais da ampliación das dimensións de avaliación, existen varias liñas de
mellora de arquitectura que poderían reforzar o rendemento e a robustez do
sistema RAG analizado neste traballo. En particular, a literatura recente
sinala que decisións relativas á segmentación do texto, ao reranking dos
documentos recuperados e á selección dos conxuntos de avaliación teñen un
impacto significativo na calidade final das respostas xeradas.

Unha primeira extensión relevante sería a adopción dunha estratexia de
\textit{small-to-big chunking}. Este enfoque consiste en empregar fragmentos
de tamaño reducido durante a fase de recuperación, co obxectivo de maximizar
a precisión e a discriminación semántica do retriever, e posteriormente
expandir eses fragmentos a unidades de contexto máis amplas na fase de
xeración. Deste modo, o modelo xerador dispón dun contexto máis rico e
cohesionado, preservando ao mesmo tempo a relevancia local identificada na
recuperación inicial. Estudos recentes sinalan que este tipo de estratexias
axudan a mitigar a perda de contexto e melloran a coherencia factual das
respostas, especialmente en tarefas de preguntas complexas \cite{wang2023chunking,wang-etal-2024-searching}.

Outra liña de traballo futuro consiste na incorporación dunha fase explícita
de \textit{reranking} baseada en modelos neuronais especializados, como
TILDEv2. Este tipo de modelos combina sinais léxicos e semánticos para refinar
a orde dos documentos recuperados, permitindo unha selección máis precisa do
contexto máis informativo antes da xeración. A integración dun reranker deste
tipo resulta especialmente relevante en escenarios con vocabulario técnico
ou especializado, nos que a recuperación puramente semántica pode resultar
insuficiente \cite{lin2022lexical}. Ademais, análises empíricas recentes mostran que a inclusión dunha etapa de
reranking pode producir melloras consistentes en métricas de recuperación e
na calidade percibida das respostas finais, mesmo cando se empregan
retrievers competitivos de base \cite{wang-etal-2024-searching}. A avaliación comparativa entre unha pipeline
sen reranking e outra que incorpore TILDEv2 permitiría cuantificar o impacto
desta capa adicional sobre diferentes métricas.

Finalmente, no ámbito da avaliación, unha extensión natural deste traballo
sería o uso de datasets estandarizados de \textit{benchmarking}, en
particular aqueles orientados a tarefas de \textit{fact checking} e
\textit{reasoning}. Este tipo de conxuntos de datos permiten avaliar non só a
corrección factual das respostas, senón tamén a capacidade do sistema para
razoar sobre evidencias múltiples e detectar inconsistencias ou información
incorrecta nos documentos recuperados. A súa incorporación facilitaría a
comparación directa con outros sistemas RAG descritos na literatura e
permitiría situar os resultados obtidos nun contexto máis amplo e
representativo do estado da arte, seguindo recomendacións metodolóxicas
recentes para a avaliación sistemática de arquitecturas RAG
\cite{rag_eval_survey_2024,wang-etal-2024-searching}.

En conxunto, estas liñas de traballo futuro apuntan cara a unha evolución do
sistema avaliado tanto a nivel arquitectónico como metodolóxico, reforzando a
súa robustez, capacidade de xeneralización e adecuación a escenarios reais de
uso. A súa exploración constitúe unha continuidade natural deste estudo e
abre a porta a avaliacións máis completas e comparables cos sistemas RAG
actuais descritos na literatura científica
\cite{rag_required_abilities_2023,lakshmanan2024rag}.

\section{Extensións da validación}
A avaliación presentada neste traballo céntrase en métricas clásicas de
recuperación e en criterios básicos de calidade da xeración, o cal resulta
adecuado para un estudo controlado cun conxunto de validación construído
manualmente. Esta elección responde a unha decisión metodolóxica orientada a
garantir reproducibilidade, trazabilidade e consistencia na avaliación, máis que
a unha limitación conceptual do enfoque.

A literatura recente sinala que o comportamento dun sistema RAG en escenarios
reais depende tamén dun conxunto de capacidades máis avanzadas (\textit{required
abilities}), cuxa avaliación resulta máis complexa e require condicións
experimentais específicas, como datasets deseñados ad hoc e un maior volume de
anotación humana \cite{rag_eval_survey_2024}.

Como liña de traballo futuro, resulta recomendable ampliar a validación cara á
avaliación destas capacidades, entre as que se inclúen:
\begin{itemize}
    \item \textbf{Noise robustness}: capacidade de xestionar documentos ruidosos semanticamente relacionados coa pregunta pero sen información útil para a resposta.
    \item \textbf{Negative rejection}: habilidade do sistema para recoñecer contextos insuficientes e evitar a xeración de respostas especulativas.
    \item \textbf{Information integration}: capacidade para combinar información procedente de múltiples documentos relevantes en preguntas complexas.
    \item \textbf{Counterfactual robustness}: aptitude para detectar e ignorar información incorrecta ou contraditoria presente nos documentos recuperados.
\end{itemize}

A incorporación destas dimensións permitiría unha avaliación máis completa do
sistema RAG, pero implicaría a ampliación do conxunto de validación actual ou a
creación de novos datasets específicos, así como un maior investimento en
anotación humana e deseño experimental. Estas extensións constitúen, por tanto,
unha continuidade natural deste traballo, orientada a aproximar a avaliación ás
condicións reais de uso e a analizar o comportamento do sistema en escenarios
máis complexos e variados \cite{rag_required_abilities_2023}.




\printbibliography
\appendix

\chapter{Máis información acerca do \textit{crawler}}

\section{\textit{Keywords} utilizadas polo crawler}
\label{app:keywords}

A continuación móstrase o conxunto completo de palabras clave utilizadas
polo \textit{crawler} para determinar a relevancia das páxinas:

\begin{multicols}{3}
\small
\begin{itemize}
    \item regulation
    \item reglamento
    \item normativa
    \item procedure
    \item procedimiento
    \item proceso
    \item form
    \item formulario
    \item solicitud
    \item guideline
    \item guia
    \item manual
    \item policy
    \item politica
    \item norma
    \item enrollment
    \item matricula
    \item inscripcion
    \item administrative
    \item administrativo
    \item academic
    \item academico
    \item calendar
    \item calendario
    \item syllabus
    \item programa
    \item requirements
    \item requisitos
    \item regulamento
    \item regulación
    \item procedemento
    \item solicitude
    \item guía
    \item docente
    \item asignatura
    \item política
    \item matrícula
    \item inscrición
    \item académico
    \item convocatoria
    \item prazo
    \item prazos
    \item documentación
    \item tramite
    \item trámite
    \item ordenanza
    \item resolución
    \item circular
    \item instrucións
    \item instrucciones
    \item bases
    \item anexo
    \item catalog
    \item catalogo
    \item catálogo
    \item library
    \item biblioteca
    \item collection
    \item coleccion
    \item colección
    \item acquisition
    \item adquisicion
    \item adquisición
    \item loan
    \item prestamo
    \item préstamo
    \item reserve
    \item reserva
    \item interlibrary
    \item interbibliotecario
    \item reference
    \item referencia
    \item circulation
    \item circulacion
    \item circulación
    \item periodical
    \item periodico
    \item periódico
    \item journal
    \item revista
    \item archive
    \item archivo
    \item arquivos
    \item repository
    \item repositorio
    \item classification
    \item clasificacion
    \item clasificación
    \item indexing
    \item indexacion
    \item indexación
    \item cataloging
    \item catalogacion
    \item catalogación
    \item dewey
    \item isbn
    \item issn
    \item bibliographic
    \item bibliografico
    \item bibliográfico
    \item holdings
    \item fondos
    \item serials
    \item publicacions seriadas
    \item special collections
    \item coleccions especiais
    \item reading room
    \item sala de lectura
    \item stacks
    \item depósito
    \item microfilm
    \item microficha
    \item digital library
    \item biblioteca dixital
    \item opac
    \item marc
    \item application
    \item deadline
    \item plazo
    \item documentation
    \item documentacion
    \item certification
    \item certificado
    \item certificación
    \item authorization
    \item autorizacion
    \item autorización
    \item notification
    \item notificacion
    \item notificación
    \item registration
    \item registro
    \item protocol
    \item protocolo
    \item statute
    \item estatuto
    \item ordinance
    \item decree
    \item decreto
    \item resolution
    \item resolucion
    \item official
    \item oficial
    \item office
    \item oficina
    \item department
    \item departamento
    \item service
    \item servicio
    \item servizo
    \item unit
    \item unidad
    \item unidade
\end{itemize}
\end{multicols}
\section{Saída OCR da táboa de exemplo}
\label{app:OCR}
\begin{tcolorbox}[
    title=Texto OCR,
    colback=rosa,
    colframe=rosa!80!black,
    fontupper=\small,
    fonttitle=\small\bfseries,
    breakable,  % Permite dividir en varias páginas si es necesario
    boxrule=0.5pt,
    arc=3pt,
    outer arc=3pt,
    left=5pt,
    right=5pt,
    top=3pt,
    bottom=3pt,
    before skip=10pt,
    after skip=10pt,
    width=\textwidth,  % Asegura que no se salga del ancho de página
    coltitle=black]
\begin{spacing}{0.85}  % Reduce el interlineado ligeramente
=== Taboa 1 ===
fila 1: [de usuarios]-GRUPO 1 [de usuarios]-GRUPO 1 [de documentos en préstamo]-GRUPO 1 [Dias de préstamo]-GRUPO 1 [Renovaciones]-GRUPO 1 [Reservas]-GRUPO 1
fila 2: [de usuarios]-de Grado de centros prapios adscritos [de usuarios]-de Grado de centros prapios adscritos [de documentos en préstamo]-10 [Dias de préstamo]-10 dias [Renovaciones]-Indefinidas [Reservas]-Limite 10 does,
fila 3: [de usuarios]-de programa de [de usuarios]-(Erasmus, Sicue-Séneca) [de documentos en préstamo]-10 [Dias de préstamo]-10 dias [Renovaciones]-Indefinidas [Reservas]-Limite 10 does,
fila 4: [de usuarios]-Estudiantada de doble Grado, de simultaneidad [de usuarios]-Estudiantada de doble Grado, de simultaneidad [de documentos en préstamo]-10 [Dias de préstamo]-10 dias [Renovaciones]-Indefinidas [Reservas]-Limite 10 does,
fila 5: [de usuarios]-Estudiantado de grados interuniversitarios [de usuarios]-Estudiantado de grados interuniversitarios [de documentos en préstamo]-10 [Dias de préstamo]-10 dias [Renovaciones]-Indefinidas [Reservas]-Limite 10 does,
fila 6: [de usuarios]-Estudiantada da Universidad Sénior [de usuarios]-Estudiantada da Universidad Sénior [de documentos en préstamo]-10 [Dias de préstamo]-10 dias [Renovaciones]-Indefinidas [Reservas]-Limite 10 does,
fila 7: [de usuarios]-Estudiantado de MASTERES posgrados propios, los dela Universidade da Corufia [de usuarios]-Estudiantado de MASTERES posgrados propios, los dela Universidade da Corufia [de documentos en préstamo]-15 [Dias de préstamo]-21 dias [Renovaciones]-Indefinidas [Reservas]-Limite 15 does,
fila 8: [de usuarios]-Estudiantada de Trabajos de fin de grado [de usuarios]-Estudiantada de Trabajos de fin de grado [de documentos en préstamo]-15 [Dias de préstamo]-21 dias [Renovaciones]-Indefinidas [Reservas]-Limite 15 does,
fila 9: [de usuarios]-Personal de administracion en servicio (PTGAS) [de usuarios]-Personal de administracion en servicio (PTGAS) [de documentos en préstamo]-15 [Dias de préstamo]-21 dias [Renovaciones]-Indefinidas [Reservas]-Limite 15 does,
fila 10: [de usuarios]-Estudiantada de [de usuarios]-Estudiantada de [de documentos en préstamo]-35 [Dias de préstamo]-30 dias [Renovaciones]-Indefinidas [Reservas]-Limite 85 does,
fila 11: [de usuarios]-Personal investigador visitante: visitante seniar/ visitante postdactoral [de usuarios]-Personal investigador visitante: visitante seniar/ visitante postdactoral [de documentos en préstamo]-35 [Dias de préstamo]-30 dias [Renovaciones]-Indefinidas [Reservas]-Limite 85 does,
fila 12: [de usuarios]-de investigacion [de usuarios]-de investigacion [de documentos en préstamo]-35 [Dias de préstamo]-Curso académico (cada biblioteca podré excluir de este tipo de préstamo por razén de uso y disponibilidad) [Renovaciones]-Indefinidas [Reservas]-Limite 85 does,
fila 13: [de usuarios]-Personal contratada investigador [de usuarios]-Personal contratada investigador [de documentos en préstamo]-35 [Dias de préstamo]-Curso académico (cada biblioteca podré excluir de este tipo de préstamo por razén de uso y disponibilidad) [Renovaciones]-Indefinidas [Reservas]-Limite 85 does,
fila 14: [de usuarios]-GRUPOS [de usuarios]-GRUPOS [de documentos en préstamo]-GRUPOS [Dias de préstamo]-GRUPOS [Renovaciones]-GRUPOS [Reservas]-GRUPOS
fila 15: [de usuarios]-PDI da UDC (incluyendo centros adscritas), de la Fundacion UDC [de usuarios]-PDI da UDC (incluyendo centros adscritas), de la Fundacion UDC [de documentos en préstamo]-100 [Dias de préstamo]-Curso académico (cada biblioteca podré excluir de este tipo de préstamo por razén de uso y disponibilidad) [Renovaciones]-Indefinidas [Reservas]-Limite 100 does.
fila 16: [de usuarios]-Profesorado jubilado incentivado honorario [de usuarios]-Profesorado jubilado incentivado honorario [de documentos en préstamo]-100 [Dias de préstamo]-Curso académico (cada biblioteca podré excluir de este tipo de préstamo por razén de uso y disponibilidad) [Renovaciones]-Indefinidas [Reservas]-Limite 100 does.
fila 17: [de usuarios]-Profesorado visitante [de usuarios]-Profesorado visitante [de documentos en préstamo]-100 [Dias de préstamo]-Curso académico (cada biblioteca podré excluir de este tipo de préstamo por razén de uso y disponibilidad) [Renovaciones]-Indefinidas [Reservas]-Limite 100 does.
fila 18: [de usuarios]-Lectores/as [de usuarios]-Lectores/as [de documentos en préstamo]-100 [Dias de préstamo]-Curso académico (cada biblioteca podré excluir de este tipo de préstamo por razén de uso y disponibilidad) [Renovaciones]-Indefinidas [Reservas]-Limite 100 does.
fila 19: [de usuarios]-Cualquier persona ajenaa la comunidad universitaria dela UDC que sea autorizada por la Biblioteca Universitaria [de usuarios]-Cualquier persona ajenaa la comunidad universitaria dela UDC que sea autorizada por la Biblioteca Universitaria [de documentos en préstamo]-None [Dias de préstamo]-10 dias [Renovaciones]-Indefinidas [Reservas]-Limite does,


\end{spacing}
\end{tcolorbox}

\section{Progresión de páxinas \textit{retrieveadas} ao longo do crawleo}
\label{fig:crawling}
\begin{figure}[h]
  \centering
    \includegraphics[width=0.9\textwidth]{imaxes/crawl_speed.png}
    \caption{Progresión da eficiencia do \textit{crawler} ao longo do tempo}
    \label{fig:crawlerRun}
\end{figure}

\chapter{Análise do Corpus}

\section{Distribución de tipos de ficheiros}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{imaxes/formatos_documentos.png}
    \caption{Distribución de tipos de ficheiros no corpus}
    \label{fig:file_types_distribution}
\end{figure}

\section{Palabras máis frecuentes}

\begin{table}[H]
\centering
\begin{tabular}{rllr}
\toprule
\textbf{Pos.} & \textbf{Palabra} & & \textbf{Frecuencia} \\
\midrule
1  & de     & - & 385,703 \\
2  & a      & - & 113,823 \\
3  & en     & - & 102,598 \\
4  & la     & - & 102,014 \\
5  & e      & - & 90,196 \\
6  & y      & - & 77,587 \\
7  & que    & - & 73,069 \\
8  & o      & - & 57,323 \\
9  & da     & - & 49,975 \\
10 & el     & - & 48,951 \\
11 & para   & - & 43,204 \\
12 & do     & - & 40,254 \\
13 & se     & - & 35,387 \\
14 & los    & - & 35,200 \\
15 & del    & - & 33,793 \\
16 & las    & - & 29,507 \\
17 & por    & - & 27,315 \\
18 & no     & - & 25,683 \\
19 & con    & - & 25,326 \\
20 & udc    & - & 25,182 \\
\bottomrule
\end{tabular}
\caption{Top 20 palabras máis frecuentes no corpus}
\label{tab:top20}
\end{table}

\section{Palabras menos frecuentes}

\begin{table}[H]
\centering
\begin{tabular}{rllr}
\toprule
\textbf{Pos.} & \textbf{Palabra} & & \textbf{Frecuencia} \\
\midrule
1  & ricondo              & - & 1 \\
2  & acompahamento        & - & 1 \\
3  & recomendaciéns       & - & 1 \\
4  & aproximacién         & - & 1 \\
5  & nosum                & - & 1 \\
6  & climent              & - & 1 \\
7  & vengut               & - & 1 \\
8  & empar                & - & 1 \\
9  & retransmision        & - & 1 \\
10 & toxicoloxia          & - & 1 \\
11 & landeira             & - & 1 \\
12 & angelines            & - & 1 \\
13 & psicoloxicos         & - & 1 \\
14 & mase                 & - & 1 \\
15 & lameiras             & - & 1 \\
16 & cartelixornadasumisionquimicaevs & - & 1 \\
17 & conciliacións        & - & 1 \\
18 & conciliaciones       & - & 1 \\
19 & operatoria           & - & 1 \\
20 & extranjeos           & - & 1 \\
\bottomrule
\end{tabular}
\caption{Top 20 palabras menos frecuentes no corpus}
\label{tab:bottom20}
\end{table}

\chapter{Máis acerca da construción da base vectorial}
\section{\textit{Prompt} utilizado para que un llm xere contextos de \textit{chunk}}
\label{sec: prechunk}
\begin{tcolorbox}[promptbox,title={Contextual Prompt - Galician},label=prompt:contextual:gl]
\begin{Verbatim}[fontsize=\small]
Escribe unha breve frase introdutoria (máx. 1-2 oracións) 
que resuma o seguinte fragmento do documento e sirva como 
contexto:

---
[Fragmento del documento (primeros 400 caracteres)]
---

Responde soamente coa frase introdutoria en galego, sen 
repetir o texto do fragmento.
\end{Verbatim}
\end{tcolorbox}
\chapter{Máis acerca da validación do RAGsystem}


\section{Vixencia temporal}


\begin{figure}[h]
  \centering
    \includegraphics[width=0.7\textwidth]{imaxes/histograma_datas.png}
    \caption{}
    \label{fig:tempohist}
\end{figure}


\begin{figure}[h]
  \centering
    \includegraphics[width=0.9\textwidth]{imaxes/temporal.jpeg}
    \caption{}
    \label{fig:temporal}
\end{figure}





\section{Preguntas de validación}

\begin{tcolorbox}[testbox,title={Pregunta \#1}]
\textbf{Pregunta:} ¿Quién es el rector de la universidad?

\textbf{Respuesta:} Ricardo Cao Abad

\textbf{Documentos:} equipo\_reitoral\_2b7d8c43.txt
\end{tcolorbox}

% Pregunta 2
\begin{tcolorbox}[testbox,title={Pregunta \#2}]
\textbf{Pregunta:} ¿Quién encabeza el equipo rectoral?

\textbf{Respuesta:} Ricardo Cao Abad

\textbf{Documentos:} equipo\_reitoral\_2b7d8c43.txt
\end{tcolorbox}

% Pregunta 3
\begin{tcolorbox}[testbox,title={Pregunta \#3}]
\textbf{Pregunta:} Cuál es el horario habitual del Edificio Xoana Capdevielle

\textbf{Respuesta:} De lunes a viernes: de las 8:15 h a las 21.45 h

\textbf{Documentos:} horarios\_4e320c1a.txt
\end{tcolorbox}

% Pregunta 4
\begin{tcolorbox}[testbox,title={Pregunta \#4}]
\textbf{Pregunta:} Cuántos ejemplares reune la biblioteca de Informática

\textbf{Respuesta:} 25.570 ejemplares

\textbf{Documentos:} biblioteca-0\_5eff5a6a.txt
\end{tcolorbox}

% Pregunta 5
\begin{tcolorbox}[testbox,title={Pregunta \#5}]
\textbf{Pregunta:} Cuántos libros hay en la biblioteca de la facultad de informática

\textbf{Respuesta:} 25.570 ejemplares

\textbf{Documentos:} biblioteca-0\_5eff5a6a.txt
\end{tcolorbox}

% Pregunta 6
\begin{tcolorbox}[testbox,title={Pregunta \#6}]
\textbf{Pregunta:} Cuántos créditos tiene el grado en estudios de arquitectura

\textbf{Respuesta:} 300 créditos

\textbf{Documentos:} 630g02v01\_3d9b1a3f.txt
\end{tcolorbox}

% Pregunta 7
\begin{tcolorbox}[testbox,title={Pregunta \#7}]
\textbf{Pregunta:} Cuál es el horario de atención de la secretaría de la facultad de informática

\textbf{Respuesta:} El horario de atención al público en la Secretaría de la Facultad de Informática será de 9:15h a 13:45h

\textbf{Documentos:} horarios-de-atencion\_d6d236bf.txt
\end{tcolorbox}

% Pregunta 8
\begin{tcolorbox}[testbox,title={Pregunta \#8}]
\textbf{Pregunta:} Cuál es el horario de la biblioteca de la facultad de sociología en días lectivos

\textbf{Respuesta:} Días lectivos: 8.30h - 21.30h, Junio, Julio y Septiembre (hasta comienzo de curso): 9.00h - 20.00h, Agosto, Navidad, Lunes de Carnaval, Semana Santa: 9.15h - 13.45h

\textbf{Documentos:} horarios\_7642b102.txt
\end{tcolorbox}

% Pregunta 9
\begin{tcolorbox}[testbox,title={Pregunta \#9}]
\textbf{Pregunta:} Cuánto dura el grado de arquitectura

\textbf{Respuesta:} 300 créditos (equivalente a 5 años)

\textbf{Documentos:} 630g02v01\_3d9b1a3f.txt
\end{tcolorbox}

% Pregunta 10
\begin{tcolorbox}[testbox,title={Pregunta \#10}]
\textbf{Pregunta:} Cuánto créditos tengo por equipos federados propios de la UDC

\textbf{Respuesta:} 1,5 créditos ECTS por curso académico

\textbf{Documentos:} document\_cd41648a.txt
\end{tcolorbox}

% Pregunta 11
\begin{tcolorbox}[testbox,title={Pregunta \#11}]
\textbf{Pregunta:} Cuánto tiempo tengo para modificar el contrato de estudios de movilidad

\textbf{Respuesta:} Plazo de un mes desde el inicio de las actividades académicas en la universidad de destino.

\textbf{Documentos:} document\_5958ed71.txt
\end{tcolorbox}

% Pregunta 12
\begin{tcolorbox}[testbox,title={Pregunta \#12}]
\textbf{Pregunta:} Quién se encarga de gestionar las becas y las ayudas a la movilidad

\textbf{Respuesta:} Oficina de Relaciones Internacionales (ORI) en lo que no sea responsabilidad de los centros

\textbf{Documentos:} document\_5958ed71.txt
\end{tcolorbox}

% Pregunta 13
\begin{tcolorbox}[testbox,title={Pregunta \#13}]
\textbf{Pregunta:} Cuánto tiempo tengo para modificar mis asignaturas de erasmus

\textbf{Respuesta:} Plazo de un mes desde el inicio de las actividades académicas en la universidad de destino.

\textbf{Documentos:} document\_5958ed71.txt
\end{tcolorbox}

% Pregunta 14
\begin{tcolorbox}[testbox,title={Pregunta \#14}]
\textbf{Pregunta:} Cuántos créditos son los cursos de formación deportiva

\textbf{Respuesta:} 1,5 créditos ECTS cada 30 horas de formación

\textbf{Documentos:} document\_cd41648a.txt
\end{tcolorbox}

% Pregunta 15
\begin{tcolorbox}[testbox,title={Pregunta \#15}]
\textbf{Pregunta:} Número de créditos mínimos para matrícula

\textbf{Respuesta:} Los estudiantes de primer curso, por primera vez, deberán superar en ese curso académico al menos 12 créditos, si la matrícula se efectuó en el régimen de dedicación a tiempo completo, y 6 créditos en el régimen de dedicación a tiempo parcial para poder tener la consideración de estudiante de continuación de estudios

\textbf{Documentos:} dedicacion\_e.txt\_2063069294\_f7b3dfc2
\end{tcolorbox}

% Pregunta 16
\begin{tcolorbox}[testbox,title={Pregunta \#16}]
\textbf{Pregunta:} Qué tipo de prácticas hay en la facultad de informática

\textbf{Respuesta:} Prácticas curriculares y extracurriculares

\textbf{Documentos:} practicas-en-empresa\_a40b7284.txt
\end{tcolorbox}

% Pregunta 17
\begin{tcolorbox}[testbox,title={Pregunta \#17}]
\textbf{Pregunta:} Cuanto es la cantidad mínima de asignaturas en la que me puedo matricular si soy estudiante a tiempo completo

\textbf{Respuesta:} Un número no inferior a 48 créditos

\textbf{Documentos:} dedicacion\_e.txt\_2063069294\_f7b3dfc2.txt
\end{tcolorbox}

% Pregunta 18
\begin{tcolorbox}[testbox,title={Pregunta \#18}]
\textbf{Pregunta:} Cuantos libros puedo llevarme de préstamo

\textbf{Respuesta:} Depende del grupo de usuario: Grupo 1 (estudiantes de grado): 10, Grupo 2 (estudiantes de máster, TFG, PAS): 15, Grupo 3 (estudiantes de doctorado, personal investigador): 35, PDI: 100

\textbf{Documentos:} prestamo\_fb00e6da.txt
\end{tcolorbox}

% Pregunta 19
\begin{tcolorbox}[testbox,title={Pregunta \#19}]
\textbf{Pregunta:} Cuantos días de préstamo me corresponden si soy estudiante de doctorado

\textbf{Respuesta:} 30 días

\textbf{Documentos:} prestamo\_fb00e6da.txt
\end{tcolorbox}

% Pregunta 20
\begin{tcolorbox}[testbox,title={Pregunta \#20}]
\textbf{Pregunta:} Quien es el coordinador responsable de relaciones internacionales en la facultad de informática

\textbf{Respuesta:} Diego Andrade

\textbf{Documentos:} coordinadores-academicos\_867aace4.txt
\end{tcolorbox}

% Pregunta 21
\begin{tcolorbox}[testbox,title={Pregunta \#21}]
\textbf{Pregunta:} Cuantas plazas hay para el grado en Inteligencia Artificial

\textbf{Respuesta:} 50

\textbf{Documentos:} NotasCorte\_C\_2025\_Plazas.txt\_2063069294\_91ca9fd9.txt
\end{tcolorbox}

% Pregunta 22
\begin{tcolorbox}[testbox,title={Pregunta \#22}]
\textbf{Pregunta:} Que grados de ciencias de la salud hay en el campus de A Coruña

\textbf{Respuesta:} Grado en Enfermería, Grado en Fisioterapia, Grado en Logopedia, Grado en Terapia Ocupacional

\textbf{Documentos:} NotasCorte\_C\_2025\_Plazas.txt\_2063069294\_91ca9fd9.txt
\end{tcolorbox}

% Pregunta 23
\begin{tcolorbox}[testbox,title={Pregunta \#23}]
\textbf{Pregunta:} Qué permite la tarjeta universitaria

\textbf{Respuesta:} La tarjeta universitaria es la credencial que permite la identificación de todos los integrantes de la comunidad universitaria, brinda acceso a múltiples servicios tecnológicos y constituye un avanzado sistema de información, gestión, acreditación, préstamo bibliotecario, acceso a recintos

\textbf{Documentos:} tui\_7df940d2.txt
\end{tcolorbox}

% Pregunta 24
\begin{tcolorbox}[testbox,title={Pregunta \#24}]
\textbf{Pregunta:} Qué tengo que hacer para usar la tarjeta universitaria en digital

\textbf{Respuesta:} Debes añadir o actualizar tu fotogtafía

\textbf{Documentos:} tui\_7df940d2.txt, emision\_2feeeba7.txt
\end{tcolorbox}

% Pregunta 25
\begin{tcolorbox}[testbox,title={Pregunta \#25}]
\textbf{Pregunta:} Cual es la fecha límite de firma de actas para TFG/TFM
\textbf{Respuesta:} 30 de septiembre de 2026
\textbf{Documentos:} document\_9c5fad96.txt


\end{tcolorbox}

\section{\textit{Prompts} utilizados para as diferentes chamadas aos modelos}
\label{sec: prompts}
\subsection{\textit{Prompts para o caso de resposta a partir de documentos recuperados}}

\begin{tcolorbox}[promptbox,title={Retrieval Prompt - English},label=prompt:retrieval:en]
\begin{Verbatim}[fontsize=\small]
You're a RAG system of the University of A Coruña (UDC).
Use the following context from documents and the conversation 
history (if any) to answer the question.
Be concise and extract important information from the text. 
If the question refers to something mentioned earlier in the 
conversation, use that information.
If you don't know, politely say you don't know instead of 
making up an answer.
The answer should be pleasant and clear. Always check the 
currency of the documents, each one will have a date within 
its metadata, always try to use the latest information in 
case of conflicts between sources. If a date isn't available, 
try to infer it from the context.
IMPORTANT: Always mention the date of the information you're 
providing (e.g., "According to the document from September 
2024..."). This helps users know how current the information is.

Context from documents: {context}

{history}

Question: {input}

Answer:
\end{Verbatim}
\end{tcolorbox}

% Prompt Spanish
\begin{tcolorbox}[promptbox,title={Retrieval Prompt - Spanish},label=prompt:retrieval:es]
\begin{Verbatim}[fontsize=\small]
Eres un sistema RAG de la Universidad de A Coruña (UDC).
Usa el siguiente contexto de los documentos y el historial 
de conversación (si existe) para responder a la pregunta.
Sé conciso y extrae información importante del texto. Si la 
pregunta hace referencia a algo mencionado anteriormente en 
la conversación, usa esa información.
Si no sabes, di educadamente que no sabes en lugar de 
inventar una respuesta.
La respuesta debe ser agradable y clara. Siempre verifica 
la vigencia de los documentos, cada uno tendrá una fecha 
en sus metadatos, intenta siempre usar la información más 
reciente en caso de conflictos entre fuentes. Si no hay 
fecha disponible, intenta inferirla del contexto.
IMPORTANTE: Siempre menciona la fecha de la información que 
proporcionas (ej: "Según el documento de septiembre de 
2024..."). Esto ayuda a los usuarios a saber qué tan actual 
es la información.

Contexto de los documentos: {context}

{history}

Pregunta: {input}

Respuesta:
\end{Verbatim}
\end{tcolorbox}

% Prompt Galician
\begin{tcolorbox}[promptbox,title={Retrieval Prompt - Galician},label=prompt:retrieval:gl]
\begin{Verbatim}[fontsize=\small]
Es un sistema RAG da Universidade da Coruña (UDC).
Responde SEMPRE en galego e NUNCA en portugués.
Usa o seguinte contexto dos documentos e o historial de 
conversación (se existe) para responder á pregunta.
Sé conciso e extrae información importante do texto. Se a 
pregunta fai referencia a algo mencionado anteriormente na 
conversación, usa esa información.
Se non sabes, di educadamente que non o sabes en lugar de 
inventar unha resposta.
A resposta debe ser agradable e clara. Sempre verifica a 
vixencia dos documentos, cada un terá unha data nos seus 
metadatos, intenta sempre usar a información máis recente 
en caso de conflitos entre fontes. Se non hai data 
dispoñible, intenta inferila do contexto.
IMPORTANTE: Sempre menciona a data da información que 
proporcionas (ex: "Segundo o documento de setembro de 
2024..."). Isto axuda aos usuarios a saber o actual que 
é a información.

Contexto dos documentos: {context}

{history}

Pregunta: {input}

Resposta:
\end{Verbatim}
\end{tcolorbox}

\newpage

\subsection{\textit{Prompts} para a resposta sen recuperación}

% No Retrieval English
\begin{tcolorbox}[promptbox,title={No Retrieval Prompt - English},label=prompt:noretrieval:en]
\begin{Verbatim}[fontsize=\small]
Answer the following question directly. Use conversation 
history if relevant.
{history}
Question: {input}
Answer:
\end{Verbatim}
\end{tcolorbox}

% No Retrieval Spanish
\begin{tcolorbox}[promptbox,title={No Retrieval Prompt - Spanish},label=prompt:noretrieval:es]
\begin{Verbatim}[fontsize=\small]
Responde directamente a la siguiente pregunta. Usa el 
historial si es relevante.
{history}
Pregunta: {input}
Respuesta:
\end{Verbatim}
\end{tcolorbox}

% No Retrieval Galician
\begin{tcolorbox}[promptbox,title={No Retrieval Prompt - Galician},label=prompt:noretrieval:gl]
\begin{Verbatim}[fontsize=\small]
Responde directamente á seguinte pregunta en galego 
(NON en portugués). Usa o historial se é relevante.
{history}
Pregunta: {input}
Resposta:
\end{Verbatim}
\end{tcolorbox}

\newpage

\subsection{\textit{Prompts} para o modelo de clasificación e reescritura de \textit{query}}

% Classification English
\begin{tcolorbox}[promptbox,title={Classification Prompt - English},label=prompt:classification:en]
\begin{Verbatim}[fontsize=\small]
You are a university assistant analyzing if a student's 
question requires searching in university documents 
(regulations, guides, academic procedures, course 
information, etc.).

Student asked: {question}

Recent conversation history:
{history}

Analyze if this question needs information from university 
documents or can be answered from:
1. General knowledge or common courtesy responses
2. Previous conversation context
3. Greetings, thanks, clarifications about previous answers

If NO retrieval needed (greetings, thanks, clarifications), 
respond: NO_RETRIEVAL
If retrieval IS needed (academic info, regulations, 
procedures), respond with an optimized search query 
(max 15 words).

Examples:
- "Hello" -> NO_RETRIEVAL
- "Thanks for the info" -> NO_RETRIEVAL
- "Can you repeat that?" -> NO_RETRIEVAL
- "What are the enrollment deadlines?" -> 
  enrollment deadlines registration periods

Your response:
\end{Verbatim}
\end{tcolorbox}

% Classification Spanish
\begin{tcolorbox}[promptbox,title={Classification Prompt - Spanish},label=prompt:classification:es]
\begin{Verbatim}[fontsize=\small]
Eres un asistente universitario analizando si la pregunta 
de un estudiante requiere buscar en documentos de la 
universidad (normativas, guías, procedimientos académicos, 
información de cursos, etc.).

El estudiante preguntó: {question}

Historial reciente de conversación:
{history}

Analiza si esta pregunta necesita información de documentos 
universitarios o puede responderse con:
1. Conocimiento general o respuestas de cortesía
2. Contexto de la conversación previa
3. Saludos, agradecimientos, aclaraciones sobre respuestas 
   anteriores

Si NO necesita búsqueda (saludos, agradecimientos, 
aclaraciones), responde: NO_RETRIEVAL
Si SÍ necesita búsqueda (info académica, normativas, 
procedimientos), responde con una query optimizada 
(máx 15 palabras).

Ejemplos:
- "Hola" -> NO_RETRIEVAL
- "Gracias por la información" -> NO_RETRIEVAL
- "¿Puedes repetir eso?" -> NO_RETRIEVAL
- "¿Cuáles son los plazos de matrícula?" -> 
  plazos matrícula períodos inscripción

Tu respuesta:
\end{Verbatim}
\end{tcolorbox}

% Classification Galician
\begin{tcolorbox}[promptbox,title={Classification Prompt - Galician},label=prompt:classification:gl]
\begin{Verbatim}[fontsize=\small]
Es un asistente universitario analizando se a pregunta dun 
estudante require buscar en documentos da universidade 
(normativas, guías, procedementos académicos, información 
de cursos, etc.). Responde SEMPRE en galego e NUNCA en portugués.


O estudante preguntou: {question}

Historial recente de conversación:
{history}

Analiza se esta pregunta necesita información de documentos 
universitarios ou pode responderse con:
1. Coñecemento xeral ou respostas de cortesía
2. Contexto da conversa previa
3. Saúdos, agradecementos, aclaracións sobre respostas 
   anteriores

Se NON necesita busca (saúdos, agradecementos, aclaracións), 
responde: NO_RETRIEVAL
Se SI necesita busca (info académica, normativas, 
procedementos), responde cunha query optimizada 
(máx 15 palabras).

Exemplos:
- "Ola" -> NO_RETRIEVAL
- "Grazas pola información" -> NO_RETRIEVAL
- "Podes repetir iso?" -> NO_RETRIEVAL
- "Cales son os prazos de matrícula?" -> 
  prazos matrícula períodos inscrición

A túa resposta:
\end{Verbatim}
\end{tcolorbox}



\section{Resultados validación RAGsystem}
\subsection{\textit{Heatmaps} de varias métricas}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imaxes/heatmaps/metricas_heatmaps.png}
    \caption{Heatmaps das métricas de validación}
    \label{fig:heatmap_metrics}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imaxes/heatmaps/metricas_combinadas_heatmap.png}
    \caption{Heatmap combinado de todas las métricas normalizadas}
    \label{fig:heatmap_combined}
\end{figure}

\subsection{\textit{Surface plots} de varias métricas}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imaxes/heatmaps/surface_plots.png}
    \caption{Surface plots de Faithfulness y Relevance}
    \label{fig:surface_plots}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imaxes/heatmaps/surface_plots_contour.png}
    \caption{Surface plots con contornos de Faithfulness y Relevance}
    \label{fig:surface_plots_contour}
\end{figure}


\subsection{Comparación de métricas para diferentes valores de perso de BM25 co mellor \textit{chunk size} (2048)}
\begin{table}[h]
\centering
\begin{minipage}{0.45\textwidth}
\centering
\caption{Faithfulness según BM25 Weight (Chunk Size = 2048)}
\label{tab:faithfulness_2048}
\begin{tabular}{cc}
\hline
\textbf{BM25 Weight} & \textbf{Faithfulness} \\
\hline
0.0 & 0.985 \\
0.2 & 1.000 \\
0.4 & 0.970 \\
0.8 & 0.963 \\
1.2 & 0.963 \\
1.6 & 0.968 \\
\hline
\end{tabular}
\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
\centering
\caption{Relevance según BM25 Weight (Chunk Size = 2048)}
\label{tab:relevance_2048}
\begin{tabular}{cc}
\hline
\textbf{BM25 Weight} & \textbf{Relevance} \\
\hline
0.0 & 0.612 \\
0.2 & 0.628 \\
0.4 & 0.656 \\
0.8 & 0.868 \\
1.2 & 0.896 \\
1.6 & 0.884 \\
\hline
\end{tabular}
\end{minipage}
\end{table}
\end{document}
