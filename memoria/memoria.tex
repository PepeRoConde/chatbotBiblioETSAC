\documentclass[12pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\usepackage[galician]{babel}
\usepackage{csquotes}

\usepackage{array}
\usepackage{booktabs}            % \toprule \midrule \bottomrule
\usepackage{tabularx}   
\usepackage{verbatim}
\usepackage{tcolorbox}
\usepackage{float}
\usepackage{multicol}
\tcbuselibrary{breakable}
\usepackage[style=ieee,backend=bibtex]{biblatex}  % o style=apa, ieee, etc.
\addbibresource{referencias.bib}

\makeatletter
\let\@makecaption\relax
\makeatother

% Fonts: Palatino for body, Helvetica for headers
\usepackage{mathpazo} % Palatino
\usepackage{helvet}
\usepackage{microtype}

% Decorative initials
\input Eichenla.fd
\newcommand*\initfamily{\usefont{U}{Eichenla}{xl}{n}}
\usepackage{lettrine}

% Colors
\usepackage{xcolor}
\definecolor{techblue}{RGB}{0,51,102}
\definecolor{rosa}{RGB}{196,45,137}
\definecolor{lightgray}{RGB}{100,100,100}

% Headers and footers
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small\textsf{\nouppercase{\leftmark}}}
\fancyhead[R]{\small\textcolor{lightgray}{\thepage}}
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0pt}

% Chapter and section styling
\usepackage{titlesec}
\titleformat{\chapter}[hang]
  {\normalfont\LARGE\bfseries\sffamily\color{rosa}}
  {\thechapter.}{15pt}{}
\titlespacing*{\chapter}{0pt}{-20pt}{30pt}

\titleformat{\section}
  {\normalfont\Large\bfseries\sffamily\color{rosa}}
  {\thesection}{1em}{}

\titleformat{\subsection}
  {\normalfont\large\bfseries\sffamily}
  {\thesubsection}{1em}{}

% Better spacing
\usepackage{setspace}
\setstretch{1.1}
\setlength{\parskip}{0.4em}
\setlength{\parindent}{15pt}

% Table of contents styling
\usepackage{tocloft}
\renewcommand{\cfttoctitlefont}{\LARGE\bfseries\sffamily\color{rosa}}
\renewcommand{\cftchapfont}{\bfseries\sffamily}
\renewcommand{\cftsecfont}{\sffamily}

% Hyperlinks
\usepackage[colorlinks=true,linkcolor=rosa,citecolor=techblue,urlcolor=techblue]{hyperref}

\title{\scshape\Huge\color{rosa}Chatbot para a documentación e normativa da UDC}
\author{
  Marcelo Ferreiro Sánchez\\
  Marcos Grobas Martínez\\
  José Romero Conde
}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
\noindent 
O obxectivo do proxecto é desenvolver un chatbot capaz de solventar dúbidas
acerca do funcionamiento dos procesos burocráticos e de documentación da
Universidade da Coruña (UDC). Para conseguilo optamos por unha arquitectura
xenerativa aumentada por recuperación (RAG), técnica moi empleada para mellorar
o desempeño de chatbots baseados en LLM cando buscan información específica dun
dominio sobre o que o modelo de linguaxe orixinal non foi entrenado. 
\end{abstract}

\tableofcontents
\clearpage

\chapter{Introdución}
\lettrine[lines=3,lraise=0.1,findent=2pt,nindent=0em]{\initfamily{A}}{}burocracia
de calquera campo pode chegar a ser moi complexa e pode chegar a consumir moito
tempo e recursos ás persoas que teñen que lidiar con ela. Os procesos
universitarios non son unha excepción e moitas das persoas involucradas neles
(sexan, alumnos, profesores ou persoal administrativo) os poden atopar
inabarcables ou imposibles de navegar sen axuda.

Neste contexto, apreciouse como podería ser de gran utilidade o desenvolvemento 
dun chatbot capaz de responder a preguntas relacionadas coa documentación e 
normativa da Universidade seguindo a gran tendencia da actualidade de empregar 
chatbots para diversas tarefas.

O obxectivo deste proxecto é desenvolver un chatbot que poida simplificar e 
explicar \textbf{referindo sempre ás fontes burocráticas oficiais} os procesos 
burocráticos e de documentación da Universidade da Coruña (UDC).

O sistema é resultado da unión de compoñentes e técnicas xa ben coñecidas, 
sempre tendo en mente o obxectivo a cumprir. Polo tanto, tratouse máis ben 
dunha tarefa de aplicación e adaptación de técnicas e ferramentas xa existentes 
nun caso particular, antes que de deseño ou resolución de novos problemas.

Se ben este traballo está circunscrito no contexto da asignatura de Técnicas 
Avanzadas de Procesamiento de Linguaxe Natural (TAPLN), debido á súa natureza 
e obxectivo, gran parte do tempo invertido no proxecto dedicouse á tarefa de 
recolección de información para o RAG.

Non existindo unha 'base de datos' oficial da UDC sobre a que un usuario poda 
descargar toda a documentación relativa ao centro, senón que atópase esta 
repartida nas páxinas web dos seus diferentes centros, foi necesario deseñar 
unha solución que nos permita extraela a partir dos seus portais oficiais.

Este tipo de tarefas non son novas no mundo da informática, de feito pertencen 
a unha área máis que consolidada chamada Recuperación de Información (IR) e 
tales métodos que buscan, extraen e organizan información disposta en webs html 
son coñecidos como \emph{crawlers}, parte esencial do traballo final pois para 
asegurar que o sistema sexa capaz de responder á maioría de dúbidas dos 
usuarios, é necesario ter un corpus de toda información mínimamente relevante 
acerca do funcionamento interno da universidade.




\chapter{Solución proposta}
\lettrine[lines=3,lraise=0.1,findent=2pt,nindent=0em]{\initfamily{M}}{}ostrarase
nesta sección a arquitectura xeral do sistema e posteriormente describirase cada
un dos seus compoñentes, sendo estos principalmente o \emph{RAGsystem} e o \emph{Crawler}.

\section{A Arquitectura}
Fundamentalmente e como indicouse antes, o sistema componse de dúas partes
relativamente independientes: \emph{RAGsystem}, que será un modelo de linguaxe grande
(LLM) xa adestrado que recibirá xunto con cada consulta de usuario, unha serie
de documentos (ou fragmentos dos mesmos) para responder mellor á mesma, e por
outra parte, un sistema de \emph{crawling} que ocuparase de navegar as diversas páxinas
e portais da UDC recolectando aquelas que considere que poden conter información
relevante. \\ \\ 
Nas siguientes subseccións explicaranse en detalle o funcionamento interno de
cada parte e cómo interactúan entre elas. Optouse por unha orde de exposición
que siga o fluxo de execución do sistema, é dicir, comezando polo \emph{Crawler}
e seguindo polo \emph{RAGsystem}. Sopesouse seguir a orde cronolóxica do
desenvolvemento do sistema mais concluíuse que introduciría demasiadas exégesis
e reviraría demasiado e sen utilidade a narrativa desta memoria. De calquera
forma, explicarase a evolución das partes que máis cambios sufriron ao longo da
súa implementación.



\section{O \emph{Crawler}} Considerouse que a posesión dun bo volume de datos
sería crucial para resolver o problema a tratar, na maioría dos casos as dúbidas
burocráticas resólvense encontrando o documento adecuado, e de non telo, o
sistema veríase obrigado a comuinicarlle ao usuario que non ten acceso á tal ou
cal información, voltándose completamente inútil. \\ É por iso que a
Recuperación de Información xoga un papel crucial para o RAG. 
\subsection{Selección de páxinas relevantes}
Sendo así, o primeiro problema a solucionar é o de deseñar un bo criterio do 
que é un \textbf{documento relevante} para a aplicación. Se ben tal tarefa 
pódese complicar \textit{ad infinitum} e é un área de estudo activa aínda 
nestes días [\cite{Pezzuti_2025}], neste caso optouse por un enfoque moito máis 
sinxelo, baseándose primariamente na premisa de que esta tarefa non require de 
conxuntos masivos de datos. Só é necesario navegar un certo número de URLs 
(principalmente do directorio raíz de cada facultade), non a totalidade da web, 
polo que pódese permitir descargar páxinas e documentos potencialmente 
pouco relevantes. A información a colleitar ten un límite de tamaño finito e 
razoable: nun escenario extremo, mesmo descargando todas as URLs da UDC, 
estaríase lonxe de requirir terabytes de almacenamento, como sí acontecería 
nun \textit{crawler} de propósito xeral. \\ \\

Deste xeito, a solución proposta sitúase como un método arcaico aínda que funcional,
unha asignación de relevancia binaria (relevante ou non relevante) mediante
\textit{keywords}. Este enfoque, se ben simple, remite aos métodos de
\textit{focused crawling} pioneiros [\cite{Chakrabarti1999}] que sentaron as
bases da recuperación de información temática na web. \\ \\As palabras clave
utilizadas son fixas e propias do ámbito académico e do vocabulario burocrático,
aparecendo tanto en galego, coma en castelán e inglés (véxase o
Apéndice~\ref{app:keywords} para a lista completa).

\subsection{Procesado dos contidos de cada páxina}
Unha vez unha páxina estímase como relevante, é necesario procesar seu contido,
para este caso, procurar presentalo en texto plano, evitando ao máximo posible
decoradores. Mais nunha páxina atópase máis que texto, especialmente neste caso
de uso, moita información burocrática útil para un usario final atoparase nun
documento PDF ligado ao URL, é por iso que o \textit{crawler} tamén os procesa e
converte en texto plano listo para que posteriormente un LLM poda leelos sen
maior complicación. \\ \\ 
Non obstante, este enfoque presenta unha limitación importante: información que
se atope unicamente en imaxes (capturas de pantalla, carteis dixitalizados ou
documentos escaneados) permanece invisible para o \textit{crawler}. \\ Tal
debilidade do sistema fíxose obvia nas primeiras fases de testeo do
\textit{chatbot}, pois este non era capaz de responder a unha pregunta moi
sinxela e básica para os estudantes: "Cantos libros pódense emprestar?". Tras
investigar a casuística e comprobarse que o
\href{https://www.udc.es/es/biblioteca/servizos/prestamo/}{URL onde figura tal
información} foi efectivamente analizada polo crawler, caéuse na conta de que,
se ben a información figura nunha táboa dentro da páxina, esta está en formato
imaxe [ver \ref{figprestamos}], polo que próbase que é necesario aproveitar
mellor a información de cada páxina para cumplir os obxectivo establecido.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{imaxes/prestamos.png}
    \caption{ Táboa de préstamos}
    \label{figprestamos}
\end{figure}



\subsubsection{Procesado de imaxes mediante OCR}
O recoñecemento óptico de caracteres (OCR polas súas siglas en inglés) é unha
técnica que permite extraer texto a partir de imaxes dixitais, se ben o seu uso
máis típico é a dixitalización de documentos físicos escaneados, serve para
calquera imaxe que conteña caracteres, como é o caso. 

Neste caso, implementouse mediante a librería \textit{pytesseract} unha
interface en \textit{Python} do motor OCR \texttt{Tesseract}, creado
inicialmente por HP e mantido actualmente por Google. 

Procesar cada imaxe presente nun URL pode semexar moi custoso
computacionalmente, mais a extracción de texto mediante OCR é verdadeiramente
rápida, isto sumado a que a maioría de imaxes son irrelevantes e de moi pequeno
tamano, otorga a capacidade de poder procesar todas as presentes en calquera
documento sen apenas engadir latencia ao sistema. Como exemplo, o tempo de
procesado de OCR na imaxe da táboa de préstamos [\ref{figprestamos}] foi de
$0.6280$ segundos. \\ \\ Demostrado que é posible e relativamente sinxelo á vez
que barato procesar arquivos de imaxe, é necesario agora demostrar que tal texto
é fidedigno ao realmente existente na mesma. 


Un exemplo que demostra á perfección un caso de uso real é precisamente a táboa
mencionada anteriormente, o texto extráido en crú pódese ver no
apéndice~\ref{app:OCR}. Revisándoo, o texto extráido non asemexa nada parecido á
táboa orixinal, mais hai que ter en mente que non é necesario que sexa
intelixible para o usuario final, senón para o LLM que o debe de analizar. Unha
forma rápida de comrpobar que o chatbot poida ser capaz de entender o texto
extraído (coa complicación de que neste caso está en formato táboa) é pedirlle
mediante un prompt no portal online dalgún LLM comercial, que refaga a táboa por
nós con esa información. Fíxose tal experimento usando ChatGPT-5 e a táboa que
reconstruiu foi a seguinte:
\begin{table}[H]
\centering
\scriptsize
\begin{tabular}{@{}p{0.18\textwidth} p{0.3\textwidth} ccc@{}}
\toprule
\textbf{Grupo} & \textbf{Tipo de usuarios} & \textbf{Nº docs} & \textbf{Días} & \textbf{Renov.} \\
\midrule
\textbf{1} & Estud. Grao (centros propios/adscritos), Mobilidade, Dobre Grao, Graos interuniv., Univ. Sénior & 10 & 10 días & Indef. (Lím. 10) \\
\midrule
\textbf{2} & Estud. másteres/posgraos propios (Fund. UDC), Estud. TFG, PTGAS & 15 & 21 días & Indef. (Lím. 15) \\
\midrule
\textbf{3} & Estud. Doutoramento, Inv. visitante/senior, Inv. predoc./posdoc & 35 & 30 días & Indef. (Lím. 35) \\
\midrule
\textbf{4} & Becarios inv., Pers. contr. inv. \textit{(Exclusión posible)} & 35 & Curso acad. & Indef. (Lím. 35) \\
\midrule
\textbf{5} & PDI UDC (inc. adscritos), Fund. UDC, Prof. emérito/xub./hon., Prof. visitante, Lectores \textit{(Exclusión posible)} & 100 & Curso acad. & Indef. (Lím. 100) \\
\midrule
\textbf{6} & Persoal externo á UDC, Pers. autoriz. Biblioteca & 6 & 10 días & Indef. (Lím. 6) \\
\bottomrule
\end{tabular}
\caption{Táboa reconstruida mediante LLM (ChatGPT-5)}
\end{table}

Se ben existe certa información que o LLM obviou por ser incompleta, a
información importante está presente, demostrando que os LLMs son capaces de
reconstruir e interpretar a información extraída mediante OCR, incluso cando
esté representada en formatos mais complexos como o é unha táboa. 

\subsection{Funcionamento interno do \textit{Crawler}}

A implementación proposta usa da librería \textit{Python BeautifulSoup} para
navegar a rede e extraer información das páxinas. O proceso comeza cunha lista
de URLs semente que representa os portais principais da universidade
(concretamente a \textit{homepage} de cada facultade). Para cada URL, o sistema
descarga o contido HTML, extrae todos os enlaces e imaxes presentes na páxina, e
identifica documentos PDF que conteñan termos relacionados coa burocracia
universitaria segundo a lista de \textit{keywords} antes exposta. Os recursos
descargados almacénanse de forma organizada no sistema de ficheiros local,
mentres que un sistema de metadatos rexistra información sobre cada recurso para
optimizar futuras execucións, concretamente garda o \textit{etag} e a data de
última modificación de cada páxina, ademáis da data de descarga.

En canto ás imaxes, aplícase OCR a todas as presentes en cada documento. O
proceso realízase en dúas fases consecutivas: primeiro procésase coa libraría
\texttt{img2table} (deseñada para extraer texto de táboas en imaxes) e, se esta
primeira fase non extrae un número mínimo de caracteres, entón aplícase un
segundo OCR utilizando \texttt{pytesseract} de xeito estándar. O texto extraído
por OCR intégrase directamente no contido textual da páxina á que pertence a
imaxe: engádese ao ficheiro de texto correspondente cun \textit{header} que
indica a súa orixe (\texttt{[TÁBOA OCR]} ou \texttt{[IMAXE OCR]}), permitindo
así conservar tanto o texto HTML como o contido visual nun único documento
estruturado.

Decídese se gardar o texto extraído ou non segundo se presenta máis dun mínimo
de caracteres definido. Todo este proceso realízase ao final de
\textit{crawlear} cada páxina: os arquivos de imaxe vanse engadindo a unha pila,
e esta é procesada unha vez xa se extraeron as hiperreferencias a outras páxinas
e os documentos PDF.

Para acelerar o proceso de \textit{crawling} aplicáronse técnicas de
programación concurrente. É posible establecer un número de traballadores aos
cales se lles asignará unha URL como base desde onde iniciar o crawler, deste
xeito, é posible ter múltiples crawlers simultáneamente navegando a rede da
universidade. Para non xerar problemas de lectura/escritura nos ficheiros onde
se escriben os metadatos ou o rexistro de páxinas visitadas, implementáronse
\textit{locks}, deste xeito dous \textit{crawlers} non poderán escribir á vez
nun mesmo documento. Implementar esta técnica foi de gran utilidade, pois a
navegación e descarga de páxinas web vai facéndose máis lenta segundo o tempo de
\textit{crawling}, xa que é máis difícil atopar páxinas relevantes non
visitadas; no apéndice~\ref{fig:crawlerRun} pódense consultar gráficas acerca
dun crawleo que o confirman.

\section{Análise dos datos obtidos mediante o \textit{Crawler}} Tras un facer un
\textit{crawl} sobre as  \textit{homepages} das facultades e escolas da UDC,
obtiveronse un total de 4966 documentos, dos cales 2668 son páxinas
\textit{HTML} e 2298 son documentos \textit{PDF} (véxase~\ref{fig:file_types_distribution}).

Debido a que esta práctica está tan enlazada coas técnicas de Recuperación da
Información clásicas, pareceu interesante realizar unha análise máis exploratoria
típica no sector. En concreto estudar a distribución das palabras do vocabulario
e lonxitude dos documentos: 

\begin{table}[h]
\centering
\caption{Estadísticas del corpus}
\label{tab:corpus_stats}
\begin{tabular}{lr}
\hline
\textbf{Métrica} & \textbf{Valor} \\
\hline
Arquivos procesados & 4.966 \\
Total de caracteres & 75.088.461 \\
Total de palabras & 10.164.265 \\
Tamaño del vocabulario & 73.640 \\
Palabras únicas (hapax legomena) & 15.889 \\
\hline
\end{tabular}
\end{table}

Atopamos que o \textit{corpus} obtido alcanza os 10 millóns de palabras, cun
vocabulario de 73.640 palabras ([\ref{tab:corpus_stats}]). Chama a atención o
elevado número de \textit{hapax legomena}, estas son aquelas palabras cunha
única instancia na colección completa, un 20\% do vocabulario pertence a esta
clase, o cal pode dar a pensar que unha gran cantidade de elas son faltas de
ortografía (xa sexan debidas ao erro humano de quen as escribiu ou na técnica de
OCR). 

Se ben podería ser así, un estudo posterior mostra o contrario, sen embargo, só
230 de tales palabras son faltas ortográficas, e 30 delas foron xeradas polo OCR.

O fenómeno de que unha porcentaxe tan elevada do vocabulario teña tan pouco uso
non é exclusivo deste corpus, senón que é unha propiedade universal dos idiomas
naturais descrita pola lei de Zipf. Esta lei establece que a frecuencia dunha
palabra é inversamente proporcional ao seu rango na distribución de frecuencias.
En outras palabras, un pequeno número de palabras moi frecuentes coexiste cunha
longa cola de palabras raras, como se pode apreciar na Figura~\ref{figZipf} e~\ref{figEDA}.



\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imaxes/zipf.png}
    \caption{~Frecuencia de termos en diversas linguas [\cite{wikipedia_zipf}]}
    \label{figZipf}
\end{figure}

Ademais, cúmprese o principio de Pareto: aproximadamente o 20\% das palabras
mais frecuentes do vocabulario cobren o (aproximadamente) 80\% das ocorrencias
totais, mentres que para alcanzar o 80\% das ocorrencias só se necesita o 80\%
do vocabulario (Figura~\ref{figEDA}). No caso deste corpus este principio e
aínda máis esaxerado e estremo, chegaríamos a ese 80\% só co 2.1\% do
vocabulario, e se o extenderamos ao 20\% o \textit{coverage} sería dun 97.5\%.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{imaxes/analisis_corpus.png}
    \caption{Gráficos de distribución de lonxitude de documentos e frecuencia de termos}
    \label{figEDA}
\end{figure}


A distribución das lonxitudes dos documentos (Figura~\ref{figEDA}, esquerda) 
revela unha gran cantidade de documentos moi curtos. A mediana sitúase en 4200
caracteres, mentres que a media alcanza os 15121 caracteres, o que indica unha 
distribución asimétrica con presenza de documentos extensos que elevan a media. 
Esta heteroxeneidade na lonxitude non é de extrañar pois existen moitas páxinas 
web cun contido moi limitado que só mostran unha serie de ligazóns ou documentos 
para descargar. De feito, algunhas URLs teñen a única finalidade de mostrar unha 
ou varias imaxes sen texto asociado. No presente \textit{crawleo} atopáronse 115 
páxinas completamente baleiras (0 caracteres), ben por conter unicamente imaxes 
sen texto extraíble por OCR, ben por tratarse de páxinas de redirección ou navegación 
pura.








\section{O \textit{RAGsystem}}

O sistema RAG (Retrieval-Augmented Generation) implementado constitúe o núcleo
do chatbot, combinando técnicas de recuperación de información con modelos de
linguaxe xerativos. O proceso de resposta a unha consulta desenvólvese nun fluxo
secuencial e optimizado:

Inicialmente, a consulta do usuario pasa por un módulo de \textit{clasificación}
realizado por un modelo de linguaxe lixeiro (Claude Haiku) para determinar se
require recuperación de documentación. Cando é necesaria, a mesma consulta é
\textit{reescrita} (\textit{query rewriting}) para mellorar a súa formulación
tanto para a busca semántica como léxica.

Para a recuperación, empregase un sistema \textit{híbrido} que combina busca
densa (mediante embeddings semánticos e similitude coseno en FAISS) e busca
léxica (usando BM25, unha evolución do TF-IDF). As puntuacións de ambos métodos
fusiónanse con pesos determinados empiricamente,
seleccionando os $k$ fragmentos de texto máis relevantes da base de documentos
da universidade.

Os documentos recuperados, xunto coa consulta orixinal e o historial de
conversación (de lonxitude configurable), intégranse nun prompt estruturado.
Este pasa a un modelo de linguaxe grande (Claude Sonnet) escollido pola súa
capacidade de razoamento e, especialmente, pola súa efectividade na comunicación
entre axentes e o seguimento de instrucións complexas
[\cite{claude-agents-2024}]. O modelo xera así unha resposta precisa
fundamentada na documentación oficial.

O sistema enriquece cada documento recuperado con metadatos que inclúen as súas
procedencias (hipervínculos), datas (de actualización da páxina), puntuacións de
relevancia tanto da busca densa como da léxica, garantindo total trazabilidade e
permitindo a verificación das fontes utilizadas en cada resposta.

\subsection{Construción da base de vectores}
[\cite{lewis2020retrieval}] A base de vectores (\textit{vectorstore}) constrúese
a partir dos documentos recollidos e previamente convertidos a texto plano
(.txt) polo \textit{crawler}. Cada documento é fragmentado en varios
\textit{chunks} de tamaño configurable, establecéndose tamén un \textit{overlap}
que especifica cantos \textit{tokens} comparten os fragmentos consecutivos. A
utilidade deste solapamento é impedir que referencias cruzadas ou ideas contidas
nun texto queden cortadas arbitrariamente ao final dun \textit{chunk}, xa que
nese caso o LLM non podería comprender o contexto completo.

Cada fragmento de texto (\textit{chunk}) xera, ademais do seu contido, un
conxunto de metadatos que inclúen: o hipervínculo de orixe da páxina, a data da
última actualización do documento orixinal (obtida durante o \textit{crawling})
e outros campos auxiliares para a trazabilidade. Estes metadatos almacénanse
xunto co vector resultante e son recuperados co texto durante a busca, o que
permite ao sistema referenciar a fonte exacta e avaliar a vixencia da
información.

Para o almacenamento e indexación eficiente dos \textit{embeddings}, emprégase
FAISS (\textit{Facebook AI Similarity Search})~[\cite{johnson2019billion}], unha
biblioteca optimizada para a busca de similaridade en espazos vectoriais de alta
dimensionalidade. FAISS implementa algoritmos de busca aproximada de veciños
máis próximos (ANN, \textit{Approximate Nearest Neighbors}), que permiten
realizar consultas en millóns de vectores de forma eficiente. O proceso funciona
do seguinte xeito: cada \textit{chunk} de texto convértese nun vector denso
(\textit{embedding}) mediante un modelo de linguaxe especializado; estes
vectores almacénanse, xunto cos seus metadatos, nunha estrutura de índice
optimizada; e cando se realiza unha consulta, FAISS calcula rapidamente os
vectores máis similares utilizando medidas de distancia como a similaridade
coseno ou a distancia euclidiana~[\cite{douze2024faiss}].






\subsection{O sistema de recuperación}

O sistema polo que o RAG recibe os documentos relevantes para cada consulta
recibe múltiples iteracións e cambios tras varias fases de testeo e
replanteamento teórico. Trátase dun compoñente clave do sistema e non ten unha
solución trivial, pois é un área de investigación moi activa
[\cite{systematic_rag_2025}]. Poderíase dicir que, aínda que a área de RI
(Recuperación de Información) parecía estar algo estancada nos últimos anos
debido aos bos resultados que alcanzaron os buscadores web, agora volve a verse
moi activa grazas ao xurdimento dos sistemas RAG.

Inicialmente, o sistema empregou un método de recuperación baseado
exclusivamente na similitude coseno sobre vectores FAISS. Porén, durante as
primeiras probas comprobouse que esta aproximación podía non ofrecer os
resultados esperados, xa que daba a mesma importancia a todas as palabras da
consulta, sen ter en conta cal podería ser a palabra clave máis relevante. A
maioría das consultas, especialmente aquelas de carácter burocrático, conteñen
moitas palabras comúns e repetidas ao longo da colección de documentos (como
\textit{proceso}, \textit{documento} ou \textit{normativa}), o que podía facer
que o sistema recuperase documentos pouco relevantes.

Como primeira mellora, implementouse MMR (Maximal Marginal Relevance) en lugar
da similitude coseno. A idea subxacente era que, deste xeito, non se
recuperarían documentos redundantes entre si, xa que se existisen varios
documentos moi similares, a súa información adicional para a consulta sería
limitada. Non obstante, durante a experimentación observouse que esta suposición
non se cumpría no noso dominio. É moi común atopar diferentes documentos
oficiais que repiten a mesma información, ou varias versións e revisións dun
proceso en distintos documentos. Neses casos, o sistema tendía a devolver só un
deles, perdéndose información relevante ou, incluso, indicando un proceso xa
obsoleto, ao priorizar a diversidade fronte á exhaustividade
[\cite{carbonell1998mmr}]. Esta problemática, relacionada coa vixencia temporal
dos documentos, constitúe un dos maiores retos deste proxecto (e de calquera
sistema RAG que manipule información cambiante ao longo do tempo
[\cite{grofsky2025freshness}]) e será tratada con maior detalle máis adiante, xa
que require modificacións en diversas partes do sistema.

Unha vez comprobado que o MMR non era axeitado para o noso dominio, retomouse o
enfoque orixinal, pero buscando unha maneira de discriminar mellor entre os
termos relevantes e irrelevantes da consulta. Para iso, decidiuse explorar
métodos clásicos de recuperación, como o TF-IDF (Term Frequency – Inverse
Document Frequency) [\cite{sparck_jones1972}]. A primeira aplicación consistiu
en usalo para reordenar (\textit{reranking}) os documentos xa recuperados por
FAISS. Con todo, axiña se observou que esta estratexia non ofrecía resultados
óptimos, xa que simplemente cambiaba a orde dos documentos recuperados, sen
engadir novos documentos relevantes que puidesen ser ignorados pola similitude
coseno.

A solución final adoptada foi un sistema híbrido que combina as puntuacións da
similitude coseno (recuperación densa) e do BM25 (unha mellora sobre o TF-IDF
para recuperación léxica ou dispersa), mediante pesos configurables. Despois
dunha avaliación da literatura, no inicio, estableceuse un balance de 50/50 entre
ambos métodos, un enfoque común en sistemas RAG actuais
[\cite{regulatory_hybrid_2025}, \cite{adobe_hybrid_2024}], máis unha vez
deseñado un \textit{pipeline} para realizar validación, optouse por usar tal
experimento para determinar empíricamente o mellor valor de peso, ademáis do
mellor \textit{chunk size}.

Ademais, o fluxo de recuperación intégrase dentro dunha canle máis ampla de
procesamento da consulta. Antes de realizar a búsqueda, lévasse a cabo unha
\textit{clasificación da consulta} (mediante un LLM lixeiro, como Claude Haiku)
para determinar se é necesario recuperar documentos. En caso afirmativo,
aplícase un \textit{reescrito da consulta} (\textit{query rewriting}), co
obxectivo de optimizar a súa formulación para a busca tanto no índice denso
(FAISS) como no léxico (BM25). Os documentos recuperados por este sistema
híbrido, xunto coa consulta orixinal, pásanlle finalmente a un modelo de
linguaxe máis grande (como Claude Sonnet) para xerar a resposta final.






\section{Os modelos}

A elección dos modelos de linguaxe no sistema RAG realizouse atendendo a
criterios de eficiencia, latencia e rendemento específico para cada tarefa do
fluxo. O sistema emprega de xeito estratéxico modelos de diferentes capacidades
segundo a súa función dentro da arquitectura, optimizando así o balance entre
precisión e tempo de resposta.

Para as tarefas iniciais de procesamento da consulta (clasificación para
determinar a necesidade de recuperación de documentos e reescritura
(\textit{query rewriting}) para mellorar a formulación da busca) utilízase
\textbf{Claude Haiku}. Este modelo, sendo o máis rápido e económico da familia
Claude de Anthropic, é ideal para tarefas lixeiras de comprensión e
transformación textual que non requiren razoamento profundo pero si baixa
latencia.

Para a fase central de xeración da resposta, empregase \textbf{Claude Sonnet}.
Este modelo ofrece un equilibrio óptimo entre capacidades de razoamento,
seguimento de instrucións complexas e eficiencia, sendo especialmente adecuado
para sintetizar información de múltiples documentos e producir respostas
coherentes, precisas e ben fundamentadas. A súa capacidade para traballar con
\textit{prompts} estruturados que inclúen contexto recuperado, historial de
conversación e instrucións específicas de formato resulta clave para a calidade
final do sistema.

Esta separación de responsabilidades (con modelos lixeiros para tarefas previas
e un modelo máis capaz para a xeración final) segue unha práctica común en
arquitecturas de sistemas RAG, onde se busca minimizar a latencia e o custo
computacional sen comprometer a calidade das respostas
[\cite{lakshmanan2024rag}, \cite{gao2023retrieval}].

\section{Ferramentas usadas}

\chapter{Instalación e uso}





\chapter{Validación e resultados}
% \lettrine[lines=3,lraise=0.1,findent=2pt,nindent=0em]{\initfamily{R}}{}esults presentation here.
\section{Validación do sistema RAG}

\subsection{Complexidade da validación}
A validación dun sistema Retrieval-Augmented Generation (RAG) é intrinsecamente
complexa debido á súa natureza híbrida, xa que combina dous subsistemas
conceptualmente distintos pero fortemente acoplados: o módulo de
\textit{retrieval}, encargado de seleccionar a información relevante, e o módulo
de \textit{generation}, responsable de producir a resposta final condicionada
polo contexto recuperado. Avaliar correctamente un sistema RAG implica analizar
de forma separada e conxunta ambos compoñentes, así como a súa interacción,
incrementando notablemente a dificultade do proceso de validación
\cite{rag_eval_survey_2024}.

Ademais, unha avaliación rigorosa require a disposición de conxuntos de datos
anotados e métricas específicas para cada etapa do pipeline. A literatura sinala
que a definición de \textit{ground truth} fiable —cun conxunto completo de
documentos relevantes e respostas correctas— é custosa en tempo e recursos, e
que as métricas existentes poden verse afectadas pola variabilidade na anotación
humana \cite{rag_eval_survey_2024,llm_judge_eval_2024}.

\subsection{Conxunto de validación}
Para realizar unha avaliación práctica e reproducible dentro das limitacións do
proxecto, construíuse un conxunto de validación reducido composto por \textbf{25
preguntas}. Cada pregunta está asociada a unha resposta esperada e ao documento
concreto do corpus onde se atopa a información necesaria para resolvela. Na
maioría dos casos, a información relevante localízase de forma explícita nun
único documento.

É importante destacar que esta avaliación realízase sobre un \textbf{corpus
reducido e controlado de documentos}. Este corpus representa só unha fracción do
conxunto total de documentos que o sistema RAG manexará nun contexto real, onde
se espera que haxa moitos máis documentos, algúns dos cales poderían recuperarse
sen ser necesarios para responder a consulta concreta. Traballar cun corpus
acotado permite, con todo, illar variables e analizar de forma precisa o
comportamento do sistema. En particular, pódese estudar o impacto de parámetros
como estratexias de recuperación, métricas de similitude, tamaño de chunk ou
número de documentos recuperados, aspectos relevantes no deseño práctico de
sistemas RAG \cite{rag_required_abilities_2023}.


Esta aproximación debe considerarse \textbf{subestimada e conservadora}, xa que
en escenarios reais poderían existir múltiples documentos relevantes por
consulta non cubertos neste estudo. As métricas obtidas non buscan medir o
rendemento absoluto do sistema en produción, senón servir como base experimental
para estudar o impacto relativo das distintas decisións de deseño do RAG.

\subsection{Evaluación do módulo de \textit{retrieval}} O módulo de recuperación
avalíase de forma independente mediante métricas clásicas de \textit{Information
Retrieval}, adaptadas ao contexto dun sistema RAG:

\begin{itemize}
    \item \textbf{Recall@10}: proporción de documentos relevantes que aparecen
    entre los 10 primeros resultados recuperados. Calculase como a fracción de
    documentos relevantes presentes no top-10 do ranking. Aínda que presentamos
    principalmente o \textbf{recall fraccional}, convén aclarar que neste
    conxunto de validación cada pregunta adoita ter un único documento
    relevante. Polo tanto, nesta situación o recall fraccional é practicamente
    equivalente ao \textbf{recall binario}, que indica se polo menos un
    documento relevante aparece entre os top-10. Esta métrica reflicte a
    capacidade do sistema de garantir que a información esencial chega ao modelo
    xerativo.
    \item \textbf{MRR (Mean Reciprocal Rank)}: penaliza a aparición tardía do
    primeiro documento relevante no ranking. Calculase como o recíproco da
    posición do primeiro documento relevante atopado (1 se é o primeiro, 0.5 se
    é o segundo, etc.). Esta métrica reflicte a rapidez coa que o sistema
    proporciona información útil ao LLM.
    \item \textbf{Precision@10}: proporción de \textit{chunks} recuperados que
    pertencen a documentos relevantes dentro dos 10 primeiros resultados. Avalía
    a capacidade do sistema para minimizar a recuperación de información
    irrelevante, especialmente crítico en corpus grandes ou ruidosos. Esta
    métrica é a nivel de chunk, reflectindo o nivel de “ruído” que chega ao LLM.
\end{itemize}

No noso sistema, o \textbf{recall e o MRR} calcúlase a nivel de documento,
considerando cada documento como unha unidade discreta de relevancia. Isto
simplifica a avaliación e garante que se mida a efectividade do sistema en levar
información esencial ao modelo xerativo, independentemente de como os documentos
estean fragmentados en chunks para a súa utilización polo LLM. 

Pola súa banda, a \textbf{precision} calcúlase a nivel de chunk, como proporción
de fragments pertencentes a documentos relevantes entre os recuperados. Este
enfoque mixto (recall a nivel documento, precision a nivel chunk) proporciona
unha visión útil para o desempeño do sistema RAG: asegura que a información
clave está dispoñible para o LLM, ao mesmo tempo que avalía a calidade do
material recuperado.

\subsection{Evaluación da xeración}
A avaliación do módulo de xeración céntrase en dúas dimensións complementarias:

\begin{itemize}
    \item \textbf{Answer Relevance}: mide se a resposta aborda correctamente a
    pregunta e evita información irrelevante. Esta métrica non xulga a
    veracidade, só a pertinencia.
    \item \textbf{Answer Faithfulness}: avalía se as afirmacións contidas na
    resposta están efectivamente respaldadas polo contexto recuperado polo
    módulo de \textit{retrieval}, detectando posibles alucinacións ou
    información non soportada.
\end{itemize}

\subsubsection{Mecanismo de avaliación: \textit{LLM-as-judge}} Para automatizar
a avaliación empregouse un modelo de linguaxe avanzado (\textbf{GPT-5.2}) como
avaliador (\textit{LLM-as-judge}), garantindo capacidade suficiente para xulgar
de forma coherente e consistente as respostas do xerador
\cite{llm_judge_eval_2024}. Este enfoque permite unha avaliación máis detallada
que as métricas clásicas, incorporando aspectos de completitude, coherencia e
consistencia co contexto.

\paragraph{Faithfulness}
O LLM analiza cada resposta dividíndoa en afirmacións atómicas e comproba se
cada unha está efectivamente respaldada polo contexto recuperado. O score final,
entre 0 e 1, representa a proporción de afirmacións verificadas. Ademais, xérase
unha explicación detallada que identifica que afirmacións fallaron e por que,
permitindo unha maior transparencia na avaliación e a detección de posibles
alucinacións ou inclusión de información externa ao contexto.

\paragraph{Relevance}
A relevancia mide se a resposta aborda todos os puntos da pregunta de forma
concisa e útil, evitando información irrelevante ou redundante. Tamén retorna un
score entre 0 e 1 e unha explicación que describe posibles omisións ou exceso de
información.

\paragraph{Beneficios do enfoque}

O uso de \textit{LLM-as-judge} permite:
\begin{itemize}
    \item Avaliar fidelidade e pertinencia de respostas en linguaxe natural de forma consistente e reproducible.
    \item Detectar matices de completitude, coherencia e relevancia que métricas de IR tradicionais non capturan.
    \item Reducir a dependencia do etiquetado humano para a avaliación detallada de respostas.
\end{itemize}


\subsubsection{Uso do mecanismo de avaliación como métrica}
Anteriormente fíxose referencia a como empregariamos o \textit{pipeline} de
avaliación para atopar un máximo no espacio de hiperparámetros do modelo, sendo
estes o \textit{chunk size} e o peso entre a busca densa e a dispersa.

Tal experimentación requiriu dunha \textit{grid search} que mediu cinco métricas
para cada combinación de valores: tres propias de Recuperación de Información
(\textit{Recall}, \textit{Precision} e \textit{MRR}) e dúas propias da
avaliación con \textit{LLM-as-judge} (\textit{Faithfulness} e
\textit{Relevance}). Tras promediar os valores para cada pregunta, puidéronse
construir \textit{heatmaps} para cada unha das medicións (ver
Figura~\ref{fig:heatmap_metrics}).

métricas para valores máis altos do peso asignado a BM25 (busca léxica) fronte á
busca densa (FAISS). A puntuación final de cada documento no sistema híbrido 
calcúlase mediante a combinación lineal:

\begin{equation}
Score_{final} = Score_{denso} + \alpha \cdot Score_{disperso}
\label{eq:score_hibrido}
\end{equation}



onde $\alpha$ representa o peso relativo de BM25. Cando $\alpha > 1$, como no 
valor óptimo de 1.6 atopado, a busca léxica ten maior influencia na selección 
final. Isto indica que, para o dominio específico da documentación
burocrática universitaria, a recuperación baseada en coincidencia de termos
clave é especialmente efectiva. As consultas neste contexto adoitan incluír
nomes propios de formularios, códigos de procedementos ou termos técnicos moi
específicos, onde a recuperación léxica supera á semántica pura. Este fenómeno é
consistente coa literatura que destaca a superioridade de BM25 en dominios con
vocabulario especializado e baixa variación lexical [\cite{lin2022lexical}].
Ademais, a natureza formal e estándar da linguaxe administrativa fai que os
documentos relevantes compartan termos exactos coas consultas, situación onde os
métodos de recuperación tradicional baseados en termos aínda ofrecen vantaxes
sobre os enfoques puramente semánticos.

Debido a que é necesario elixir un par de valores para os hiperparámetros,
optouse por aqueles que maximizan a métrica de \textit{Relevance} obtida
mediante \textit{LLM-as-judge}. Esta decisión baséase na premisa de que a
relevancia percibida da resposta final é o criterio de calidade máis alineado
coa experiencia do usuario final nun sistema de preguntas e respostas. Mentres
que métricas tradicionais de RI como \textit{Precision} e \textit{Recall} miden
a eficacia da recuperación de documentos, a \textit{Relevance} evalúa
directamente se o contido xerado responde de maneira útil e adecuada á intención
da consulta orixinal. Maximizar esta métrica prioriza que o sistema produza
respostas substanciais e directamente aplicables, por riba doutras
consideracións como a exhaustividade bruta (\textit{Recall}) ou a minimización
de información irrelevante (\textit{Precision}) no contexto recuperado. Esta
aproximación está avalada por investigacións recentes que suxiren que, en
sistemas RAG interactivos, a relevancia da resposta xerada é o predictor máis
forte da satisfacción do usuario [\cite{saad2024evaluating}].

Polo tanto, tras facer un \textit{surface plot}
(Figura~\ref{fig:surface_plots_contour}) da \textit{Relevance} (e tamén da
\textit{Faithfulness}), optouse polo par de valores no seu cumio (que o
maximizan), sendo este un peso de 1.6 para BM25 e un \textit{chunk size} de 2048
\textit{tokens}. Tamén se realizou un \textit{heatmap} de todas estas métricas
promediadas (Figura~\ref{fig:heatmap_combined}), onde o par de valores con
mellor puntuación segue sendo o mesmo.

Non é de estrañar que o \textit{chunk size} óptimo para este dominio sexa
relativamente grande. A documentación burocrática e administrativa universitaria
adoita estar estruturada en seccións longas e autocontidas (como procedementos
completos, regulamentos ou guías), onde o contexto local é crucial para
comprender requisitos, excepcións ou pasos interrelacionados. Fragmentos
demasiado pequenos poden separar información conceptualmente unida, dificultando
que o modelo de linguaxe xere respostas coherentes e exhaustivas. Este resultado
é consistente coa literatura sobre recuperación en dominios técnicos e legais,
onde se recomiendan tamaños de fragmento maiores para preservar a integridade
semántica dos documentos [\cite{wang2023chunking}].



\subsection{Consideracións sobre o corpus reducido}
O estudo realizouse sobre un \textbf{corpus reducido e controlado de
documentos}. Isto permite illar variables e analizar o impacto de parámetros
como: as estratexias de recuperación (TF-IDF, híbridas, reranking) ou o tamaño
de chunk e superposición

En escenarios de produción, con moitos máis documentos dispoñibles, é altamente
probable que o sistema recupere unha maior cantidade de documentos irrelevantes,
o que afectará especialmente á \textbf{precision@10}. O estudo realizado neste
corpus reducido proporciona unha visión inicial sobre a capacidade do RAG para
filtrar información relevante en presenza de ruído documental, e serve como base
experimental para estudar o impacto relativo das decisións de deseño.

\subsection{Limitacións}
O conxunto reducido introduce certas limitacións que afectan a toda a validación:
\begin{itemize}
    \item Non reflicte a heteroxeneidade nin a escala real do corpus.
    \item Subrepresenta casos que requiren integración multi-documento.
    \item Posibles omisións no etiquetado humano.
    \item As métricas non son directamente extrapolables a produción.
\end{itemize}

A avaliación proposta proporciona unha visión relativa do impacto das decisións
de deseño do RAG, e non debe interpretarse como unha medida directa do seu
rendemento absoluto en escenarios de produción \cite{rag_eval_survey_2024}.


\chapter{Conclusions e traballos futuros}

\section{Extensións arquitectónicas e metodolóxicas}

Ademais da ampliación das dimensións de avaliación, existen varias liñas de
mellora de arquitectura que poderían reforzar o rendemento e a robustez do
sistema RAG analizado neste traballo. En particular, a literatura recente
sinala que decisións relativas á segmentación do texto, ao reranking dos
documentos recuperados e á selección dos conxuntos de avaliación teñen un
impacto significativo na calidade final das respostas xeradas.

Unha primeira extensión relevante sería a adopción dunha estratexia de
\textit{small-to-big chunking}. Este enfoque consiste en empregar fragmentos
de tamaño reducido durante a fase de recuperación, co obxectivo de maximizar
a precisión e a discriminación semántica do retriever, e posteriormente
expandir eses fragmentos a unidades de contexto máis amplas na fase de
xeración. Deste modo, o modelo xerador dispón dun contexto máis rico e
cohesionado, preservando ao mesmo tempo a relevancia local identificada na
recuperación inicial. Estudos recentes sinalan que este tipo de estratexias
axudan a mitigar a perda de contexto e melloran a coherencia factual das
respostas, especialmente en tarefas de preguntas complexas \cite{wang2023chunking,wang-etal-2024-searching}.

Outra liña de traballo futuro consiste na incorporación dunha fase explícita
de \textit{reranking} baseada en modelos neuronais especializados, como
TILDEv2. Este tipo de modelos combina sinais léxicos e semánticos para refinar
a orde dos documentos recuperados, permitindo unha selección máis precisa do
contexto máis informativo antes da xeración. A integración dun reranker deste
tipo resulta especialmente relevante en escenarios con vocabulario técnico
ou especializado, nos que a recuperación puramente semántica pode resultar
insuficiente \cite{lin2022lexical}. Ademais, análises empíricas recentes mostran que a inclusión dunha etapa de
reranking pode producir melloras consistentes en métricas de recuperación e
na calidade percibida das respostas finais, mesmo cando se empregan
retrievers competitivos de base \cite{wang-etal-2024-searching}. A avaliación comparativa entre unha pipeline
sen reranking e outra que incorpore TILDEv2 permitiría cuantificar o impacto
desta capa adicional sobre diferentes métricas.

Finalmente, no ámbito da avaliación, unha extensión natural deste traballo
sería o uso de datasets estandarizados de \textit{benchmarking}, en
particular aqueles orientados a tarefas de \textit{fact checking} e
\textit{reasoning}. Este tipo de conxuntos de datos permiten avaliar non só a
corrección factual das respostas, senón tamén a capacidade do sistema para
razoar sobre evidencias múltiples e detectar inconsistencias ou información
incorrecta nos documentos recuperados. A súa incorporación facilitaría a
comparación directa con outros sistemas RAG descritos na literatura e
permitiría situar os resultados obtidos nun contexto máis amplo e
representativo do estado da arte, seguindo recomendacións metodolóxicas
recentes para a avaliación sistemática de arquitecturas RAG
\cite{rag_eval_survey_2024,wang-etal-2024-searching}.

En conxunto, estas liñas de traballo futuro apuntan cara a unha evolución do
sistema avaliado tanto a nivel arquitectónico como metodolóxico, reforzando a
súa robustez, capacidade de xeneralización e adecuación a escenarios reais de
uso. A súa exploración constitúe unha continuidade natural deste estudo e
abre a porta a avaliacións máis completas e comparables cos sistemas RAG
actuais descritos na literatura científica
\cite{rag_required_abilities_2023,lakshmanan2024rag}.

\section{Extensións da validación}
A avaliación presentada neste traballo céntrase en métricas clásicas de
recuperación e en criterios básicos de calidade da xeración, o cal resulta
adecuado para un estudo controlado cun conxunto de validación construído
manualmente. Esta elección responde a unha decisión metodolóxica orientada a
garantir reproducibilidade, trazabilidade e consistencia na avaliación, máis que
a unha limitación conceptual do enfoque.

A literatura recente sinala que o comportamento dun sistema RAG en escenarios
reais depende tamén dun conxunto de capacidades máis avanzadas (\textit{required
abilities}), cuxa avaliación resulta máis complexa e require condicións
experimentais específicas, como datasets deseñados ad hoc e un maior volume de
anotación humana \cite{rag_eval_survey_2024}.

Como liña de traballo futuro, resulta recomendable ampliar a validación cara á
avaliación destas capacidades, entre as que se inclúen:
\begin{itemize}
    \item \textbf{Noise robustness}: capacidade de xestionar documentos ruidosos semanticamente relacionados coa pregunta pero sen información útil para a resposta.
    \item \textbf{Negative rejection}: habilidade do sistema para recoñecer contextos insuficientes e evitar a xeración de respostas especulativas.
    \item \textbf{Information integration}: capacidade para combinar información procedente de múltiples documentos relevantes en preguntas complexas.
    \item \textbf{Counterfactual robustness}: aptitude para detectar e ignorar información incorrecta ou contraditoria presente nos documentos recuperados.
\end{itemize}

A incorporación destas dimensións permitiría unha avaliación máis completa do
sistema RAG, pero implicaría a ampliación do conxunto de validación actual ou a
creación de novos datasets específicos, así como un maior investimento en
anotación humana e deseño experimental. Estas extensións constitúen, por tanto,
unha continuidade natural deste traballo, orientada a aproximar a avaliación ás
condicións reais de uso e a analizar o comportamento do sistema en escenarios
máis complexos e variados \cite{rag_required_abilities_2023}.




\printbibliography
\appendix

\chapter{Máis información acerca do \textit{crawler}}

\section{\textit{Keywords} utilizadas polo crawler}
\label{app:keywords}

A continuación móstrase o conxunto completo de palabras clave utilizadas
polo \textit{crawler} para determinar a relevancia das páxinas:

\begin{multicols}{3}
\small
\begin{itemize}
    \item regulation
    \item reglamento
    \item normativa
    \item procedure
    \item procedimiento
    \item proceso
    \item form
    \item formulario
    \item solicitud
    \item guideline
    \item guia
    \item manual
    \item policy
    \item politica
    \item norma
    \item enrollment
    \item matricula
    \item inscripcion
    \item administrative
    \item administrativo
    \item academic
    \item academico
    \item calendar
    \item calendario
    \item syllabus
    \item programa
    \item requirements
    \item requisitos
    \item regulamento
    \item regulación
    \item procedemento
    \item solicitude
    \item guía
    \item docente
    \item asignatura
    \item política
    \item matrícula
    \item inscrición
    \item académico
    \item convocatoria
    \item prazo
    \item prazos
    \item documentación
    \item tramite
    \item trámite
    \item ordenanza
    \item resolución
    \item circular
    \item instrucións
    \item instrucciones
    \item bases
    \item anexo
    \item catalog
    \item catalogo
    \item catálogo
    \item library
    \item biblioteca
    \item collection
    \item coleccion
    \item colección
    \item acquisition
    \item adquisicion
    \item adquisición
    \item loan
    \item prestamo
    \item préstamo
    \item reserve
    \item reserva
    \item interlibrary
    \item interbibliotecario
    \item reference
    \item referencia
    \item circulation
    \item circulacion
    \item circulación
    \item periodical
    \item periodico
    \item periódico
    \item journal
    \item revista
    \item archive
    \item archivo
    \item arquivos
    \item repository
    \item repositorio
    \item classification
    \item clasificacion
    \item clasificación
    \item indexing
    \item indexacion
    \item indexación
    \item cataloging
    \item catalogacion
    \item catalogación
    \item dewey
    \item isbn
    \item issn
    \item bibliographic
    \item bibliografico
    \item bibliográfico
    \item holdings
    \item fondos
    \item serials
    \item publicacions seriadas
    \item special collections
    \item coleccions especiais
    \item reading room
    \item sala de lectura
    \item stacks
    \item depósito
    \item microfilm
    \item microficha
    \item digital library
    \item biblioteca dixital
    \item opac
    \item marc
    \item application
    \item deadline
    \item plazo
    \item documentation
    \item documentacion
    \item certification
    \item certificado
    \item certificación
    \item authorization
    \item autorizacion
    \item autorización
    \item notification
    \item notificacion
    \item notificación
    \item registration
    \item registro
    \item protocol
    \item protocolo
    \item statute
    \item estatuto
    \item ordinance
    \item decree
    \item decreto
    \item resolution
    \item resolucion
    \item official
    \item oficial
    \item office
    \item oficina
    \item department
    \item departamento
    \item service
    \item servicio
    \item servizo
    \item unit
    \item unidad
    \item unidade
\end{itemize}
\end{multicols}
\section{Saída OCR da táboa de exemplo}
\label{app:OCR}
\begin{tcolorbox}[
    title=Texto OCR,
    colback=rosa,
    colframe=rosa!80!black,
    fontupper=\small,
    fonttitle=\small\bfseries,
    breakable,  % Permite dividir en varias páginas si es necesario
    boxrule=0.5pt,
    arc=3pt,
    outer arc=3pt,
    left=5pt,
    right=5pt,
    top=3pt,
    bottom=3pt,
    before skip=10pt,
    after skip=10pt,
    width=\textwidth,  % Asegura que no se salga del ancho de página
    coltitle=black]
\begin{spacing}{0.85}  % Reduce el interlineado ligeramente
[Tipos de usuarios

N? de documentos en préstamo

Días de préstamo

Renovaciones

Reservas

GRUPO 1

Estudiantado de Grado de centros propios y adscritos

Estudiantado de programa de movilidad (Erasmus, Sicue-Séneca)

Estudiantado de doble Grado, de simultaneidad 10 10 días Indefinidas | Límite 10 docs.
Estudiantado de grados interuniversitarios
Estudiantado da Universidad Séntor
GRUPO 2
Estudiantado de MASTERES e posgrados propios, incluyendo los
dela Fundación Universidade da Coruña . ,
15 21 días Indefinidas | Límite 15 docs.
Estudiantado de Trabajos de fin de grado.
Personal de administración en servicio (PTGAS)
GRUPO 3
Estudiantado de Doctorado 35 30 días Indefinidas | Límite 35 does.
Personal investigador visitante; visitant tant
'ersonal investigador visitante: visitante senior] visitante 35 30 días indefinidas | Límite 38 docs
predoctoral o postdactoral
GRUPO 4
Becarios/as de investigación Curso académico
Personal contratado investigador (cada biblioteca podrá excluir
35 de este tipo de préstamo Indefinidas | Límite 35 docs.
documentos par razón de uso y
disponibilidad)
GRUPO 5
PDI da UDC (incluyendo centros adscritos), de la Fundación UDC Curso académico
Profesorado emérito, jubilado incentivado y honorario (cada biblioteca podrá excluir
Profesorado visitante 100 de este tipo de préstamo Indefíridas | Límite 100 docs.
Lectores/as documentos par razón de uso y
disponibilidad)
GRUPO 6
Cual ! idad taria de la UDC
cualquier persona ajena a la comunidad universitaria dela 6 10 días indefinidas | Límite 6 docs

que sea autorizada por la Biblioteca Universitaria


\end{spacing}
\end{tcolorbox}

\section{Progresión de páxinas \textit{retrieveadas} ao longo do crawleo}
\label{fig:crawling}
\begin{figure}
  \centering
    \includegraphics[width=0.9\textwidth]{imaxes/crawl_speed.png}
    \caption{Progresión da eficiencia do \textit{crawler} ao longo do tempo}
    \label{fig:crawlerRun}
\end{figure}

\chapter{Análise do Corpus}

\section{Distribución de tipos de ficheiros}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{imaxes/formatos_documentos.png}
    \caption{Distribución de tipos de ficheiros no corpus}
    \label{fig:file_types_distribution}
\end{figure}

\section{Palabras máis frecuentes}

\begin{table}[H]
\centering
\begin{tabular}{rllr}
\toprule
\textbf{Pos.} & \textbf{Palabra} & & \textbf{Frecuencia} \\
\midrule
1  & de     & - & 385,703 \\
2  & a      & - & 113,823 \\
3  & en     & - & 102,598 \\
4  & la     & - & 102,014 \\
5  & e      & - & 90,196 \\
6  & y      & - & 77,587 \\
7  & que    & - & 73,069 \\
8  & o      & - & 57,323 \\
9  & da     & - & 49,975 \\
10 & el     & - & 48,951 \\
11 & para   & - & 43,204 \\
12 & do     & - & 40,254 \\
13 & se     & - & 35,387 \\
14 & los    & - & 35,200 \\
15 & del    & - & 33,793 \\
16 & las    & - & 29,507 \\
17 & por    & - & 27,315 \\
18 & no     & - & 25,683 \\
19 & con    & - & 25,326 \\
20 & udc    & - & 25,182 \\
\bottomrule
\end{tabular}
\caption{Top 20 palabras máis frecuentes no corpus}
\label{tab:top20}
\end{table}

\section{Palabras menos frecuentes}

\begin{table}[H]
\centering
\begin{tabular}{rllr}
\toprule
\textbf{Pos.} & \textbf{Palabra} & & \textbf{Frecuencia} \\
\midrule
1  & ricondo              & - & 1 \\
2  & acompahamento        & - & 1 \\
3  & recomendaciéns       & - & 1 \\
4  & aproximacién         & - & 1 \\
5  & nosum                & - & 1 \\
6  & climent              & - & 1 \\
7  & vengut               & - & 1 \\
8  & empar                & - & 1 \\
9  & retransmision        & - & 1 \\
10 & toxicoloxia          & - & 1 \\
11 & landeira             & - & 1 \\
12 & angelines            & - & 1 \\
13 & psicoloxicos         & - & 1 \\
14 & mase                 & - & 1 \\
15 & lameiras             & - & 1 \\
16 & cartelixornadasumisionquimicaevs & - & 1 \\
17 & conciliacións        & - & 1 \\
18 & conciliaciones       & - & 1 \\
19 & operatoria           & - & 1 \\
20 & extranjeos           & - & 1 \\
\bottomrule
\end{tabular}
\caption{Top 20 palabras menos frecuentes no corpus}
\label{tab:bottom20}
\end{table}

\section{Resultados validación RAGsystem}
\subsection{\textit{Heatmaps} de varias métricas}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imaxes/heatmaps/metricas_heatmaps.png}
    \caption{Heatmaps das métricas de validación}
    \label{fig:heatmap_metrics}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imaxes/heatmaps/metricas_combinadas_heatmap.png}
    \caption{Heatmap combinado de todas las métricas normalizadas}
    \label{fig:heatmap_combined}
\end{figure}

\subsection{\textit{Surface plots} de varias métricas}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imaxes/heatmaps/surface_plots.png}
    \caption{Surface plots de Faithfulness y Relevance}
    \label{fig:surface_plots}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imaxes/heatmaps/surface_plots_contour.png}
    \caption{Surface plots con contornos de Faithfulness y Relevance}
    \label{fig:surface_plots_contour}
\end{figure}


\subsection{Comparación de métricas para diferentes valores de perso de BM25 co mellor \textit{chunk size} (2048)}
\begin{table}[h]
\centering
\begin{minipage}{0.45\textwidth}
\centering
\caption{Faithfulness según BM25 Weight (Chunk Size = 2048)}
\label{tab:faithfulness_2048}
\begin{tabular}{cc}
\hline
\textbf{BM25 Weight} & \textbf{Faithfulness} \\
\hline
0.0 & 0.985 \\
0.2 & 1.000 \\
0.4 & 0.970 \\
0.8 & 0.963 \\
1.2 & 0.963 \\
1.6 & 0.968 \\
\hline
\end{tabular}
\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
\centering
\caption{Relevance según BM25 Weight (Chunk Size = 2048)}
\label{tab:relevance_2048}
\begin{tabular}{cc}
\hline
\textbf{BM25 Weight} & \textbf{Relevance} \\
\hline
0.0 & 0.612 \\
0.2 & 0.628 \\
0.4 & 0.656 \\
0.8 & 0.868 \\
1.2 & 0.896 \\
1.6 & 0.884 \\
\hline
\end{tabular}
\end{minipage}
\end{table}
\end{document}
